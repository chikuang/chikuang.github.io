<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 2 Introduction | Optimal Regression Design under Second-Order Least Squares Estimator: Theory, Algorithm and Applications</title>
<meta name="author" content="Chi-Kuang Yeh">
<meta name="description" content="Design of experiment is a sub-field in statistics that has a long history in its developments. After Sir Ronald A. Fisher’s pioneering work on the analysis of variance and fractional factorial...">
<meta name="generator" content="bookdown 0.39 with bs4_book()">
<meta property="og:title" content="Chapter 2 Introduction | Optimal Regression Design under Second-Order Least Squares Estimator: Theory, Algorithm and Applications">
<meta property="og:type" content="book">
<meta property="og:description" content="Design of experiment is a sub-field in statistics that has a long history in its developments. After Sir Ronald A. Fisher’s pioneering work on the analysis of variance and fractional factorial...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 2 Introduction | Optimal Regression Design under Second-Order Least Squares Estimator: Theory, Algorithm and Applications">
<meta name="twitter:description" content="Design of experiment is a sub-field in statistics that has a long history in its developments. After Sir Ronald A. Fisher’s pioneering work on the analysis of variance and fractional factorial...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.7.0/transition.js"></script><script src="libs/bs3compat-0.7.0/tabs.js"></script><script src="libs/bs3compat-0.7.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
          margin-bottom: 0em;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Optimal Regression Design under Second-Order Least Squares Estimator: Theory, Algorithm and Applications</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Preface</a></li>
<li><a class="active" href="intro.html"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="" href="chapter-SLSE.html"><span class="header-section-number">3</span> Optimal Regression Designs Under SLSE</a></li>
<li><a class="" href="chapter-applications.html"><span class="header-section-number">4</span> Numerical Algorithm and Applications</a></li>
<li><a class="" href="chapter:discussions.html"><span class="header-section-number">5</span> Discussions</a></li>
<li><a class="" href="final-words.html"><span class="header-section-number">6</span> Final Words</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="intro" class="section level1" number="2">
<h1>
<span class="header-section-number">2</span> Introduction<a class="anchor" aria-label="anchor" href="#intro"><i class="fas fa-link"></i></a>
</h1>
<p>Design of experiment is a sub-field in statistics that has a long history in its developments. After Sir Ronald A. Fisher’s pioneering work on the analysis of variance and fractional factorial design concepts, while working in Rothamsted Experimental Station in the 1920s and 1930s , many statisticians worked in this research area and made significant contributions. <span class="citation">Berger and Wong (<a href="references.html#ref-berger2009introduction">2009</a>)</span> gave many vital examples in the development of optimal design theory over the years, including <span class="citation">Chernoff (<a href="references.html#ref-chernoff1953locally">1953</a>)</span>, <span class="citation">Kiefer (<a href="references.html#ref-kiefer1959optimum">1959</a>)</span>, <span class="citation">Kiefer (<a href="references.html#ref-kiefer1974general">1974</a>)</span>, <span class="citation">Kiefer and Wolfowitz (<a href="references.html#ref-kiefer-wolfowitz1959optimum">1959</a>)</span>, <span class="citation">Samuel David Silvey (<a href="references.html#ref-silvey1980optimal">1980</a>)</span> and <span class="citation">Atkinson and Donev (<a href="references.html#ref-atkinson1992optimum">1992</a>)</span>. Their inputs to this field have had huge impacts towards today’s design framework. One century later, design techniques have been found to be effective and now are widely used in other disciplines, such as agriculture, engineering, environmental science, biomedical and pharmaceutical studies. See examples in <span class="citation">Crary et al. (<a href="references.html#ref-crary2000optimal">2000</a>)</span>, <span class="citation">Crary (<a href="references.html#ref-crary2002design">2002</a>)</span>, <span class="citation">Haines, Perevozskaya, and Rosenberger (<a href="references.html#ref-haines2003bayesian">2003</a>)</span>, <span class="citation">Zhou et al. (<a href="references.html#ref-zhou2003a">2003</a>)</span>, <span class="citation">Jain and Tiwari (<a href="references.html#ref-jain2003modeling">2003</a>)</span>, <span class="citation">Brosi, Armsworth, and Daily (<a href="references.html#ref-brosi2008optimal">2008</a>)</span> and <span class="citation">Schorning et al. (<a href="references.html#ref-schorning2017optimal">2017</a>)</span>. Its primary objective is to study the cause and effect between variables under some systematic approaches and procedures.</p>
<p>Over the decades, many theoretical results and algorithms have been developed to construct different kinds of optimal designs, which include factorial design, fractional factorial design, response surface design, and regression design. In this thesis, we will focus on optimal regression design under a recently proposed statistical estimator, second-order least squares estimator (SLSE) in <span class="citation">Wang and Leblanc (<a href="references.html#ref-wang2008second">2008</a>)</span>.</p>
<div id="optimal-regression-design-problem" class="section level2" number="2.1">
<h2>
<span class="header-section-number">2.1</span> Optimal regression design problem<a class="anchor" aria-label="anchor" href="#optimal-regression-design-problem"><i class="fas fa-link"></i></a>
</h2>
<p>``Regression analysis is a statistical technique for investigating and modeling the relationship between variables” <span class="citation">(<a href="references.html#ref-montgomery2012introduction">Montgomery, Peck, and Vining 2012</a>)</span>. It is one of the most widely used statistical methods to explore the relationship between variables based on observed data. Although there are different kinds of regression models, we mainly focus on one response linear and nonlinear regression models.</p>
<p>Suppose we want to study the relationship between <span class="math inline">\(\boldsymbol{x}\in \mathbb{R}^p\)</span> (a vector of explanatory variables) and <span class="math inline">\(y\)</span> (a response variable). Consider a general regression model for (<span class="math inline">\(\boldsymbol{x_i},y_i\)</span>),</p>
<p><span class="math display" id="eq:simple-regression">\[\begin{equation}
y_i=g\left(\boldsymbol{x_i};\boldsymbol{\theta}\right)+\epsilon_i,\quad ~i=1,\dots,n,
\tag{2.1}
\end{equation}\]</span>
where <span class="math inline">\(\boldsymbol{\theta}\in \mathbb{R}^q\)</span> is an unknown parameter vector, <span class="math inline">\(n\)</span> is the sample size, <span class="math inline">\(g(\cdot)\)</span> is a known linear or nonlinear expectation function depending on <span class="math inline">\(\boldsymbol{\theta}\)</span>, and <span class="math inline">\(\epsilon_i\)</span> is a random error of the regression model. The random error <span class="math inline">\(\epsilon_i's\)</span> are assumed to be independent identically distributed with zero mean and variance <span class="math inline">\(\sigma^2\)</span>. The random error terms are further assumed to be homoscedastic in this thesis. Since <span class="math inline">\(\boldsymbol{x_i}\)</span> and <span class="math inline">\(y_i\)</span> are observed data and <span class="math inline">\(g(\cdot)\)</span> is also known, the only unknown component is <span class="math inline">\(\boldsymbol{\theta}\)</span>. A question naturally comes in mind is how to estimate <span class="math inline">\(\boldsymbol{\theta}\)</span> efficiently.</p>
<p>Suppose <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> is an estimator of <span class="math inline">\(\boldsymbol{\theta}\)</span>. The design problem aims to get the most information about <span class="math inline">\(\boldsymbol{\theta}\)</span> or <span class="math inline">\(g\left(\boldsymbol{x}_i;\boldsymbol{\theta}\right)\)</span> by selecting the best probability distribution on <span class="math inline">\(\boldsymbol{x}_1,\boldsymbol{x}_2,\dots,\boldsymbol{x}_n\)</span> that maximizes some scalar functions of the Fisher’s information matrix of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. The sample points <span class="math inline">\(\boldsymbol{x}_i\)</span> and space are called design points and design space, respectively. It is known that Fisher’s information matrix is proportional to the inverse of the variance-covariance matrix of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>. Thus, the design problem aims to minimize some scalar functions of the variance-covariance matrix of <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>, which are called objective functions or loss functions. The resulted probability measure <span class="math inline">\(\xi\)</span> contains two components that are the support points and the corresponding probabilities associated with these points. The choice of the loss functions is determined based on the design interest. Various design criteria have been studied in the literature, such as A- and D-optimality criteria. D-optimality is one of the most widely used design criterion that minimizes the determinant of the variance-covariance matrix. The most desired property of D-optimal design is its scale invariant property. A-optimality minimizes the trace that leads to minimize the sum of the variances of the estimated parameters. See <span class="citation">Fedorov (<a href="references.html#ref-fedorov1972theory">1972</a>)</span>, <span class="citation">Samuel David Silvey (<a href="references.html#ref-silvey1980optimal">1980</a>)</span>, <span class="citation">Pukelsheim (<a href="references.html#ref-pukelsheim2006optimal">2006</a>)</span>, <span class="citation">Berger and Wong (<a href="references.html#ref-berger2009introduction">2009</a>)</span>, and <span class="citation">Dean et al. (<a href="references.html#ref-dean2015handbook">2015</a>)</span> for other optimality criteria.</p>
<p>Let us consider Gompertz growth model to illustrate a D-optimal design. The model is given by
<span class="math display">\[\begin{equation*}
y_i=\theta_1 e^{-\theta_2e^{-\theta_3 x_i}}+\epsilon_i,~i=1,2,\cdots,n,\quad \boldsymbol{\theta}
=\left(\theta_1,\theta_2,\theta_3\right)^\top,\quad x_i\in S,
\end{equation*}\]</span>
where <span class="math inline">\(\theta_1\)</span> describes the maximum growing capacity, <span class="math inline">\(\theta_2\)</span> explains the initial status of the subject, <span class="math inline">\(\theta_3\)</span> determines the growth rate, <span class="math inline">\(y\)</span> is the overall growth at the current time point and <span class="math inline">\(x\)</span> is the time. Note that <span class="math inline">\(x\)</span>, <span class="math inline">\(\theta_1\)</span> , <span class="math inline">\(\theta_2\)</span> and <span class="math inline">\(\theta_3\)</span> are assumed to be positive in this context. We want to study how one subject’s total growth associated with time. The model has broad applications in biological science and cancer studies. See some examples in and . Suppose the design space <span class="math inline">\(S\)</span> is <span class="math inline">\([0,10]\)</span> (i.e. <span class="math inline">\(x\in[0,10]\)</span>) and the true parameters of <span class="math inline">\(\boldsymbol{\theta}\)</span> is given by <span class="math inline">\(\boldsymbol{\theta}_o=(1,1,1)^\top\)</span>. For this model, D-optimal design aims to select the probability measure on <span class="math inline">\(S\)</span> that minimizes <span class="math inline">\(\det(\hat{\boldsymbol{\theta}})\)</span>, where <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> is the SLSE. The details of the SLSE will be discussed in Section <span class="math inline">\(\ref{section:SLSE}\)</span> and Chapter <span class="math inline">\(\ref{chapter:optimal regression under SLSE}\)</span>. The resulted probability measure under D-optimality is
<span class="math display" id="eq:gompertz-prob">\[\begin{equation}
  \xi_D^*=
\begin{bmatrix}
0.000 &amp;   1.350 &amp;  10.000\\
1/3 &amp;   1/3 &amp;  1/3
\end{bmatrix},
\tag{2.2}
\end{equation}\]</span></p>
<p>where the top row represents the support points and the second row describes the corresponding probabilities on the points. The resulted design has three support points at <span class="math inline">\(x=0.000,~1.350\)</span> and <span class="math inline">\(10.000\)</span> having equal weight (<span class="math inline">\(1/3\)</span>). The interpretation of <a href="intro.html#eq:gompertz-prob">(2.2)</a> is that we will distribute resources evenly at three points, <span class="math inline">\(0.000\)</span>, <span class="math inline">\(1.350\)</span> and <span class="math inline">\(10.000\)</span>. For instance, if the maximum number of runs available is fifteen due to the scarcity of resources, the researcher will make five observations at each of the three points. In Figure <span class="math inline">\(\ref{fig:gompertz}\)</span>, the line represents the behavior of expectation function <span class="math inline">\(g(\boldsymbol{x};\boldsymbol{\theta})\)</span> in the design space S, and the <span class="math inline">\(*\)</span> represents the support point.</p>
<p>Many studies are conducted by using ordinary least squares estimator (OLSE) as the estimator (<span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>) in optimal regression design framework. OLSE is the best linear unbiased estimator (BLUE) in the regression context. However, if the error distribution is asymmetric, the SLSE is more efficient than OLSE from <span class="citation">Wang and Leblanc (<a href="references.html#ref-wang2008second">2008</a>)</span>, which is reviewed in next section.</p>
</div>
<div id="section-SLSE" class="section level2" number="2.2">
<h2>
<span class="header-section-number">2.2</span> Second-order least squares estimator<a class="anchor" aria-label="anchor" href="#section-SLSE"><i class="fas fa-link"></i></a>
</h2>
<p>We first discuss the relationship between OLSE and SLSE, as well as the advantages of SLSE over OLSE. OLSE is an estimator to estimate the parameter vector <span class="math inline">\(\boldsymbol{\theta}\)</span> in regression model <a href="intro.html#eq:simple-regression">(2.1)</a>, which is defined to be
<span class="math display">\[\begin{equation*}
\boldsymbol{\hat{\theta}}:=\underset{\boldsymbol{\theta}}{\mathrm{argmin}}\sum_{i=1}^n
(y_i-g(\boldsymbol{x_i};\boldsymbol{\theta}) )^2.
\end{equation*}\]</span>
The assumptions for using OLSE are: the error terms are assumed to be homoscedastic and independently identically distributed with zero mean and finite constant variance. It has many desired properties such as consistency and it is the BLUE, which is widely used. In practice, however, other estimators might outperform OLSE in some scenarios. If the error distribution is asymmetric, <span class="citation">Wang and Leblanc (<a href="references.html#ref-wang2008second">2008</a>)</span> has shown that SLSE is asymptotically more efficient than OLSE. When the random errors are symmetrically distributed, SLSE and OLSE have the same asymptotic efficiency. SLSE has caught attentions in optimal regression design context due to these reasons.</p>
<p>We now review some properties of the SLSE in the regression model (<a href="intro.html#eq:simple-regression">(2.1)</a>. SLSE is defined as
<span class="math display">\[\begin{equation*}
(\boldsymbol{\hat{\theta}}^\top,\hat{\sigma}^2)^\top:=\underset{\boldsymbol{\theta},\sigma^2}{\mathrm{argmin}}\sum_{i=1}^n
\begin{pmatrix}
y_i-g(\boldsymbol{x}_i;\boldsymbol{\theta})\\
y_i^2-g^2(\boldsymbol{x}_i;\boldsymbol{\theta})-\sigma^2
\end{pmatrix}^\top
W(\boldsymbol{x_i})
\begin{pmatrix}
y_i-g(\boldsymbol{x}_i;\boldsymbol{\theta})\\
y_i^2-g^2(\boldsymbol{x}_i;\boldsymbol{\theta})-\sigma^2
\end{pmatrix}.
\end{equation*}\]</span>
Note that <span class="math inline">\(W(\boldsymbol{x_i})\)</span> is a <span class="math inline">\(2\times 2\)</span> non-negative semi-definite matrix which may or may not depend on <span class="math inline">\(\boldsymbol{x_i}\)</span> <span class="citation">(<a href="references.html#ref-wang2008second">Wang and Leblanc 2008</a>)</span>. It is clear that SLSE is a natural extension of the OLSE which is defined based on the first-order difference function (i.e. <span class="math inline">\(y_i-\mathbb{E}[y_i]=y_i-g(\boldsymbol{x}_i;\boldsymbol{\theta})\)</span>). On the other hand, SLSE is defined using not only the fist-order difference function, but also second-order difference function (i.e. <span class="math inline">\(y_i^2-\mathbb{E}[y_i^2]=y_i^2-(g^2(\boldsymbol{x}_i;\boldsymbol{\theta})+\sigma^2))\)</span>. One might think about the downsides of the SLSE after talking about the advantages of SLSE over OLSE. SLSE does have its disadvantages indeed. It is not a linear estimator and there is no closed-form solution. It requires more computational resources compared to the OLSE due to the nonlinearity. However, numerical results can be easily computed for SLSE nowadays. As the result, SLSE is a powerful alternative estimator to be considered in research studies and real-life applications.</p>
</div>
<div id="research-problem" class="section level2" number="2.3">
<h2>
<span class="header-section-number">2.3</span> Research problem<a class="anchor" aria-label="anchor" href="#research-problem"><i class="fas fa-link"></i></a>
</h2>
<p>As introduced in the previous section, <span class="citation">Wang and Leblanc (<a href="references.html#ref-wang2008second">2008</a>)</span> showed that SLSE is asymptotically more efficient than OLSE when the error distribution is asymmetric. Optimal designs under the SLSE was proposed in <span class="citation">Gao and Zhou (<a href="references.html#ref-gao2014new">2014</a>)</span>. <span class="citation">Bose and Mukerjee (<a href="references.html#ref-bose2015optimal">2015</a>)</span> <span class="citation">Yin and Zhou (<a href="references.html#ref-yin2018optimal">2017</a>)</span> and <span class="citation">Gao and Zhou (<a href="references.html#ref-gao2017d">2017</a>)</span> did further investigations, including the convexity analysis, numerical methods, transformation and scale invariance properties for both A- and D-optimality criteria. There are other commonly used design criteria under the SLSE that have not been studied in the literature. Our goal is to fill this gap by extending the results to other design criteria, as well as exploring and deriving more theoretical results for the optimal designs under the SLSE.</p>
<p>The rest of the thesis is organized as follows. Chapter 2 describes the detailed formulation of optimal regression designs under SLSE. We derive several analytical results including equivalence theorem and the number of support points in optimal designs. Chapter 3 explains how to use numerical algorithms to solve the proposed optimal regression design problems via convex programming. We also present several interesting applications of the optimal designs studied in this thesis. Chapter 4 provides concluding remarks and discusses possible future research topics. MATLAB code are given in the Appendix.</p>
</div>
<div id="main-contributions" class="section level2" number="2.4">
<h2>
<span class="header-section-number">2.4</span> Main Contributions<a class="anchor" aria-label="anchor" href="#main-contributions"><i class="fas fa-link"></i></a>
</h2>
<p>Here is a summary of the main contributions in this thesis.</p>
<ol style="list-style-type: decimal">
<li><p>We have studied the c-optimality design criterion under the SLSE, which has not been studied before.</p></li>
<li><p>We have applied Kiefer’s equivalence theorem <span class="citation">(<a href="references.html#ref-kiefer1974general">Kiefer 1974</a>)</span> to obtain the conditions for the A-, c- and D-optimal designs under the SLSE.</p></li>
<li><p>We have obtained the number of support points in optimal designs under the SLSE analytically for various regression models.</p></li>
<li><p>We have studied the generalized scale invariance property of D-optimal designs under the SLSE.</p></li>
<li><p>We have given one efficient and effective computing algorithm based on the program in MATLAB for computing optimal designs under the SLSE on discrete design spaces.</p></li>
</ol>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="index.html"><span class="header-section-number">1</span> Preface</a></div>
<div class="next"><a href="chapter-SLSE.html"><span class="header-section-number">3</span> Optimal Regression Designs Under SLSE</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#intro"><span class="header-section-number">2</span> Introduction</a></li>
<li><a class="nav-link" href="#optimal-regression-design-problem"><span class="header-section-number">2.1</span> Optimal regression design problem</a></li>
<li><a class="nav-link" href="#section-SLSE"><span class="header-section-number">2.2</span> Second-order least squares estimator</a></li>
<li><a class="nav-link" href="#research-problem"><span class="header-section-number">2.3</span> Research problem</a></li>
<li><a class="nav-link" href="#main-contributions"><span class="header-section-number">2.4</span> Main Contributions</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Optimal Regression Design under Second-Order Least Squares Estimator: Theory, Algorithm and Applications</strong>" was written by Chi-Kuang Yeh. It was last built on 2024-05-20.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
