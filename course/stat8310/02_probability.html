<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Belief function and Probability Review – STAT8310 - Bayesian Data Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03_bi-1par.html" rel="next">
<link href="./01_intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="custom-callouts.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">STAT8310 - Bayesian Data Analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/chikuang/Teaching-Stat8310"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="././STAT8310---Bayesian-Data-Analysis.pdf"> <i class="bi bi-file-pdf" role="img" aria-label="Download PDF">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./02_probability.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Belief function and Probability Review</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Quick Overview</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_probability.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Belief function and Probability Review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_bi-1par.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Inference for single parameter models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_MC.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Monte Carlo Method and its variations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./App_A-intro-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Appendix: Introduction to R</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#belief-functions" id="toc-belief-functions" class="nav-link active" data-scroll-target="#belief-functions"><span class="header-section-number">2.1</span> Belief functions</a>
  <ul class="collapse">
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">2.1.1</span> Conclusion</a></li>
  </ul></li>
  <li><a href="#events-partitions-and-bayes-rule" id="toc-events-partitions-and-bayes-rule" class="nav-link" data-scroll-target="#events-partitions-and-bayes-rule"><span class="header-section-number">2.2</span> Events, Partitions and Bayes’ Rule</a>
  <ul class="collapse">
  <li><a href="#partition-and-probability" id="toc-partition-and-probability" class="nav-link" data-scroll-target="#partition-and-probability"><span class="header-section-number">2.2.1</span> Partition and Probability</a></li>
  </ul></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence"><span class="header-section-number">2.3</span> Independence</a></li>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link" data-scroll-target="#random-variables"><span class="header-section-number">2.4</span> Random Variables</a>
  <ul class="collapse">
  <li><a href="#discrete-ramdon-variables" id="toc-discrete-ramdon-variables" class="nav-link" data-scroll-target="#discrete-ramdon-variables"><span class="header-section-number">2.4.1</span> Discrete Ramdon variables</a></li>
  <li><a href="#continuous-random-variables" id="toc-continuous-random-variables" class="nav-link" data-scroll-target="#continuous-random-variables"><span class="header-section-number">2.4.2</span> Continuous random variables</a></li>
  <li><a href="#description-of-distributions-through-quantiles-and-moments" id="toc-description-of-distributions-through-quantiles-and-moments" class="nav-link" data-scroll-target="#description-of-distributions-through-quantiles-and-moments"><span class="header-section-number">2.4.3</span> Description of distributions through quantiles and moments</a></li>
  </ul></li>
  <li><a href="#joint-disitrubiton" id="toc-joint-disitrubiton" class="nav-link" data-scroll-target="#joint-disitrubiton"><span class="header-section-number">2.5</span> Joint Disitrubiton</a>
  <ul class="collapse">
  <li><a href="#discrete-random-variables" id="toc-discrete-random-variables" class="nav-link" data-scroll-target="#discrete-random-variables"><span class="header-section-number">2.5.1</span> Discrete random variables</a></li>
  <li><a href="#continuous-random-variables-1" id="toc-continuous-random-variables-1" class="nav-link" data-scroll-target="#continuous-random-variables-1"><span class="header-section-number">2.5.2</span> Continuous random variables</a></li>
  <li><a href="#mixed-continuous-and-discrete-variables" id="toc-mixed-continuous-and-discrete-variables" class="nav-link" data-scroll-target="#mixed-continuous-and-discrete-variables"><span class="header-section-number">2.5.3</span> Mixed continuous and discrete variables</a></li>
  <li><a href="#bayes-rule-and-parameter-estimation" id="toc-bayes-rule-and-parameter-estimation" class="nav-link" data-scroll-target="#bayes-rule-and-parameter-estimation"><span class="header-section-number">2.5.4</span> Bayes’ rule and parameter estimation</a></li>
  </ul></li>
  <li><a href="#independence-random-variables" id="toc-independence-random-variables" class="nav-link" data-scroll-target="#independence-random-variables"><span class="header-section-number">2.6</span> Independence Random Variables</a></li>
  <li><a href="#exchangeability" id="toc-exchangeability" class="nav-link" data-scroll-target="#exchangeability"><span class="header-section-number">2.7</span> Exchangeability</a>
  <ul class="collapse">
  <li><a href="#independence-versus-dependence" id="toc-independence-versus-dependence" class="nav-link" data-scroll-target="#independence-versus-dependence"><span class="header-section-number">2.7.1</span> Independence versus dependence</a></li>
  <li><a href="#a-latent-parameter-model" id="toc-a-latent-parameter-model" class="nav-link" data-scroll-target="#a-latent-parameter-model"><span class="header-section-number">2.7.2</span> A latent-parameter model</a></li>
  </ul></li>
  <li><a href="#de-finettis-theorem" id="toc-de-finettis-theorem" class="nav-link" data-scroll-target="#de-finettis-theorem"><span class="header-section-number">2.8</span> de Finetti’s Theorem</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Belief function and Probability Review</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>Leading objectives:</p>
<p>be familiar with the following concepts</p>
<ul>
<li>Belief Functions</li>
<li>Probability</li>
<li>Bayes’ Rule</li>
<li>Random Variables</li>
<li>Exchangeability</li>
</ul>
</blockquote>
<section id="belief-functions" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="belief-functions"><span class="header-section-number">2.1</span> Belief functions</h2>
<p>Probability is a way to express rational beliefs.</p>
<div class="callout-definition" title="Belief Functions">
<p>A <strong>belief function</strong> <span class="math inline">\(\mathrm{Be}(\cdot)\)</span> is a function that assigns number to statements such that the large the number, the higher the degree of belief.</p>
</div>
<div class="callout-example" title="Belief function">
<p>Let <span class="math inline">\(F, G\)</span>, and <span class="math inline">\(H\)</span> be three possibly overlapping statements about the world.</p>
<p>For example:</p>
<ul>
<li>F = { a person owns a smartphone }</li>
<li>G = { a person uses social media daily }</li>
<li>H = { a person works remotely at least part of the time }</li>
</ul>
<p>or</p>
<ul>
<li>F = { a person has a graduate degree }</li>
<li>G = { a person works in a STEM field }</li>
<li>H = { a person is employed in the private sector }</li>
</ul>
<p>The perference over bets involving these statements can be used to define a belief function</p>
<ul>
<li><span class="math inline">\(\mathrm{Be}(F)&gt;\mathrm{Be}(G)\)</span> means you prefer a bet <span class="math inline">\(F\)</span> is true over that <span class="math inline">\(G\)</span> is true.</li>
</ul>
<p>Also, we want <span class="math inline">\(\mathrm{Be}(\cdot)\)</span> to describe our beliefs under certain conditions</p>
<ul>
<li><p><span class="math inline">\(\mathrm{Be}(F\mid H) &gt; \mathrm{Be}(G\mid H)\)</span> means that if we knew that <span class="math inline">\(H\)</span> were true, then we would perfer to bet that <span class="math inline">\(F\)</span> is also true over <span class="math inline">\(G\)</span> is also true.</p></li>
<li><p><span class="math inline">\(\mathrm{Be}(F\mid G) &gt; \mathrm{Be}(F\mid H)\)</span> means that if we bet on <span class="math inline">\(F\)</span>, we would perfer to do it under the condition that <span class="math inline">\(G\)</span> is true rather than <span class="math inline">\(H\)</span> is true.</p></li>
</ul>
</div>
<p>Some more notations:</p>
<ul>
<li><p>Let <span class="math inline">\(\neg\)</span> denote negation. That is, <span class="math inline">\(\neg F\)</span> is the statement that <span class="math inline">\(F\)</span> is not true.</p></li>
<li><p>Let <span class="math inline">\(F \vee G\)</span> denote the disjunction (or) of statements <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span>, meaning that at least one of <span class="math inline">\(F\)</span> or <span class="math inline">\(G\)</span> is true.</p></li>
<li><p>Let <span class="math inline">\(F \wedge G\)</span> denote the conjunction (and) of statements <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span>, meaning that both <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span> are true.</p></li>
</ul>
<div class="callout-definition" title="Axioms of Beliefs">
<p>It has been argued by many that any function that is to numerically represent our beliefs should have the following properties:</p>
<ul>
<li><p><strong>B1</strong>: <span class="math inline">\(\mathrm{Be}(\neg H\mid H) \le \mathrm{Be}(F \mid H) \le \mathrm{Be}(H \mid H)\)</span></p></li>
<li><p><strong>B2</strong>: <span class="math inline">\(\mathrm{Be}(F \vee G\mid H) \ge  \max\{\mathrm{Be}(F \mid H), \mathrm{Be}(G\mid H)\}\)</span></p></li>
<li><p><strong>B3</strong>: <span class="math inline">\(\mathrm{Be}(F \wedge G\mid H)\)</span> can be derived from <span class="math inline">\(\mathrm{Be}(G\mid H)\)</span> and <span class="math inline">\(\mathrm{Be}(F\mid G \wedge H)\)</span>.</p></li>
</ul>
</div>
<p>How should we interpret these properties, and do they make sense?</p>
<ul>
<li><p>B1 means that the number we assign to <span class="math inline">\(\mathrm{Be}(F \mid H)\)</span>, our conditional belief in <span class="math inline">\(F\)</span> given <span class="math inline">\(H\)</span>, is bounded below and above by the numbers we assign to complete disbelief <span class="math inline">\(\mathrm{Be}(\neg H \mid H)\)</span> and complete belief <span class="math inline">\(\mathrm{Be}(H \mid H)\)</span>.</p></li>
<li><p>B2 says that our belief that the truth lies in a given set of possibilities should not decrease as we add to the set of possibilities.</p></li>
<li><p>B3 is a bit trickier. To see why it makes sense, imagine you have to decide whether or not <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span> are true, knowing that <span class="math inline">\(H\)</span> is true. You could do this by first deciding whether or not <span class="math inline">\(G\)</span> is true given <span class="math inline">\(H\)</span>, and if so, then deciding whether or not <span class="math inline">\(F\)</span> is true given <span class="math inline">\(G\)</span> and <span class="math inline">\(H\)</span>.</p></li>
</ul>
<div class="callout-definition" title="Axioms of Probability">
<p>Recall the notation from (elementary) probability that, <span class="math inline">\(F\cup G\)</span> means F or G, and <span class="math inline">\(F\cap G\)</span> means F and G, and <span class="math inline">\(\emptyset\)</span> is the empty set.</p>
<ul>
<li><p><strong>P1</strong>: <span class="math display">\[
0=\mathrm{Pr}(\neg H \mid H) \leq \mathrm{Pr}(F \mid H) \leq \mathrm{Pr}(H \mid H)=1
\]</span></p></li>
<li><p><strong>P2</strong>: <span class="math display">\[\mathrm{Pr}(F \cup G \mid H)=\mathrm{Pr}(F \mid H)+\mathrm{Pr}(G \mid H),\quad \text{if}\quad F \cap G=\emptyset\]</span></p></li>
<li><p><strong>P3</strong>: <span class="math display">\[\mathrm{Pr}(F \cap G \mid H)=\mathrm{Pr}(G \mid H) \mathrm{Pr}(F \mid G \cap H)\]</span></p></li>
</ul>
</div>
<section id="conclusion" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">2.1.1</span> Conclusion</h3>
<p>You can see that, a probability function satisfy P1–P3 also satisfies B1–B3. Therefore, probability functions are a special case of belief functions, and we can use it to describe our belief.</p>
</section>
</section>
<section id="events-partitions-and-bayes-rule" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="events-partitions-and-bayes-rule"><span class="header-section-number">2.2</span> Events, Partitions and Bayes’ Rule</h2>
<div class="callout-definition" title="Partition of a set">
<p>A collectiion of sets <span class="math inline">\(\{H_1,\dots,H_K\}\)</span> is a partition of another set <span class="math inline">\(\mathcal{H}\)</span> if</p>
<ol type="1">
<li><p><span class="math inline">\(H_i \cap H_j = \emptyset\)</span> for all <span class="math inline">\(i \neq j\)</span> (mutually exclusive);</p></li>
<li><p><span class="math inline">\(\bigcup_{i=1}^K H_i = \mathcal{H}\)</span> (collectively exhaustive).</p></li>
</ol>
</div>
<p>In the context of indetifying which of several statements is true, if <span class="math inline">\(\mathcal{H}\)</span> is the set of all possible truths and <span class="math inline">\(\{H_1,\dots,H_K\}\)</span> is a partition of <span class="math inline">\(\mathcal{H}\)</span>, then exactly one set <span class="math inline">\(H_j\)</span> contains the truth.</p>
<div class="callout-example" title="Model correctness">
<p>Let <span class="math inline">\(\mathcal{H}\)</span> be the status of a statistical model.</p>
<p>Valid partitions include:</p>
<ul>
<li><span class="math inline">\(\{\text{correctly specified}, \text{misspecified}\}\)</span></li>
<li><span class="math inline">\(\{\text{underfitting}, \text{well-specified}, \text{overfitting}\}\)</span></li>
</ul>
</div>
<section id="partition-and-probability" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="partition-and-probability"><span class="header-section-number">2.2.1</span> Partition and Probability</h3>
<p>Suppose <span class="math inline">\(\{H_1,\dots,H_K\}\)</span> is a partition of <span class="math inline">\(\mathcal{H}\)</span>,<span class="math inline">\(\mathrm{Pr}(\mathcal{H})=1\)</span> and <span class="math inline">\(E\)</span> is some specific event. Then, by the axioms of probability, we have</p>
<ul>
<li><p>Law of total probability <span class="math display">\[
\sum_{k=1}^K \mathrm{Pr}(H_k)=\mathrm{Pr}\left(\bigcup_{k=1}^K H_k\right)=\mathrm{Pr}(\mathcal{H})=1
\]</span></p></li>
<li><p>Law of marginal probability <span class="math display">\[
\mathrm{Pr}(E)=\sum_{k=1}^K \mathrm{Pr}(E \cap H_k)=\sum_{k=1}^K \mathrm{Pr}(E \mid H_k) \mathrm{Pr}(H_k)
\]</span></p></li>
<li><p>Bayes’ rule <span class="math display">\[
\mathrm{Pr}(H_j \mid E)=\frac{\mathrm{Pr}(E \mid H_j) \mathrm{Pr}(H_j)}{\mathrm{Pr}(E)}=\frac{\mathrm{Pr}(E \mid H_j) \mathrm{Pr}(H_j)}{\sum_{k=1}^K \mathrm{Pr}(E \mid H_k) \mathrm{Pr}(H_k)}
\]</span></p></li>
</ul>
<div class="callout-example">
<p>A subset of the 1996 General Social Survey includes data on the education level and income for a sample of males over 30 years of age. Let {H1,H2,H3,H4} be the events that a randomly selected person in this sample is in, respectively, the lower 25th percentile, the second 25th percentile, the third 25th percentile and the upper 25th percentile in terms of income. By definition,</p>
<p><span class="math display">\[
\left\{\operatorname{Pr}\left(H_1\right), \operatorname{Pr}\left(H_2\right), \operatorname{Pr}\left(H_3\right), \operatorname{Pr}\left(H_4\right)\right\}=\{.25, .25, .25, .25\} .
\]</span></p>
<p>Note that <span class="math inline">\(\{H1,H2,H3,H4\}\)</span> is a partition and so these probabilities sum to 1. Let <span class="math inline">\(E\)</span> be the event that a randomly sampled person from the survey has a college education. From the survey data, we have <span class="math display">\[\{\mathrm{Pr}(E\mid H_1), \mathrm{Pr}(E\mid H_2),\mathrm{Pr}(E\mid H_3), \mathrm{Pr}(E\mid H_4)\} = \{.11, .19, .31, .53\}.\]</span> These probabilities do not sum to 1 - they represent the proportions of people with college degrees in the four different income subpopulations <span class="math inline">\(H_1, H_2, H_3\)</span> and <span class="math inline">\(H_4\)</span>. Now let’s consider the income distribution of the college-educated population. Using Bayes’ rule we can obtain</p>
<p><span class="math inline">\(\{\mathrm{Pr}(H_1\mid E), \mathrm{Pr}(H_2\mid E), \mathrm{Pr}(H_3\mid E), \mathrm{Pr}(H_4 \mid E)\} = \{0.09, 0.17, 0.27, 0.47\} ,\)</span> and we see that the income distribution for people in the college-educated population differs markedly from <span class="math inline">\(\{0.25, 0.25,0.25,0.25\}\)</span>, the distribution for the general population. Note that these probabilities do sum to 1 - they are the conditional probabilities of the events in the partition, given <span class="math inline">\(E\)</span>.</p>
</div>
<p>In Bayesian inference, <span class="math inline">\({H_1, . . . ,H_K}\)</span> often refer to disjoint hypotheses or states of nature and <span class="math inline">\(E\)</span> refers to the outcome of a survey, study or experiment. To compare hypotheses <em>post-experimentally</em>, we often calculate the following ratio: <span class="math display">\[
\begin{aligned}
\frac{\operatorname{Pr}\left(H_i \mid E\right)}{\operatorname{Pr}\left(H_j \mid E\right)} &amp; =\frac{\operatorname{Pr}\left(E \mid H_i\right) \operatorname{Pr}\left(H_i\right) / \operatorname{Pr}(E)}{\operatorname{Pr}\left(E \mid H_j\right) \operatorname{Pr}\left(H_j\right) / \operatorname{Pr}(E)} \\
&amp; =\frac{\operatorname{Pr}\left(E \mid H_i\right) \operatorname{Pr}\left(H_i\right)}{\operatorname{Pr}\left(E \mid H_j\right) \operatorname{Pr}\left(H_j\right)} \\
&amp; =\frac{\operatorname{Pr}\left(E \mid H_i\right)}{\operatorname{Pr}\left(E \mid H_j\right)} \times \frac{\operatorname{Pr}\left(H_i\right)}{\operatorname{Pr}\left(H_j\right)} \\
&amp; =\text { "Bayes factor" × "prior beliefs". }
\end{aligned}
\]</span> This calculation reminds us that Bayes’ rule does not determine what our <em>beliefs should be</em> after seeing the data, it only tells us how they <em>should change after seeing the data</em>.</p>
</section>
</section>
<section id="independence" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="independence"><span class="header-section-number">2.3</span> Independence</h2>
<div class="callout-definition" title="(Conditional) Independence">
<p>Two events <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span> are conditionally independent, if given <span class="math inline">\(H\)</span>, we have <span class="math inline">\(\mathrm{Pr}(F \cap G \mid H) = \mathrm{Pr}(F\mid H)\mathrm{Pr}(G\mid H)\)</span>.</p>
</div>
<p>How do we interpret conditional independence? By Axiom P3, the following is always true: <span class="math display">\[
\begin{array}{rlll}
\operatorname{Pr}(G \mid H) \operatorname{Pr}(F \mid H \cap G) \stackrel{\text { always }}{=} \operatorname{Pr}(F \cap G \mid H) &amp; \stackrel{\text { independence }}{=} \operatorname{Pr}(F \mid H) \operatorname{Pr}(G \mid H) \\
\operatorname{Pr}(G \mid H) \operatorname{Pr}(F \mid H \cap G) &amp; = &amp; \operatorname{Pr}(F \mid H) \operatorname{Pr}(G \mid H) \\
\operatorname{Pr}(F \mid H \cap G) &amp; = &amp; \operatorname{Pr}(F \mid H) .
\end{array}
\]</span></p>
<p>Thus, conditional independence implies that <span class="math inline">\(\mathrm{Pr}(F \mid H \cap G) = \mathrm{Pr}(F\mid H)\)</span>. In other words, if we know <span class="math inline">\(H\)</span> is true, and <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span> are conditionally independent given <span class="math inline">\(H\)</span>, then knowing <span class="math inline">\(G\)</span> does not change our belief about <span class="math inline">\(F\)</span>.</p>
<div class="callout-example" title="Conditional independence">
<p>Let’s consider the conditional dependence of <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span> when <span class="math inline">\(H\)</span> is assumed to be true in the following two situations:</p>
<p>Siutation 1:</p>
<ul>
<li>F = { a hospital patient is a smoker }</li>
<li>G = { a hospital patient has lung cancer }</li>
<li>H = { smoking causes lung cancer}</li>
</ul>
<p>Situation 2:</p>
<ul>
<li>F = { a student studies regularly for an exam }</li>
<li>G = { a student receives a high exam score }</li>
<li>H = { studying improves exam performance }</li>
</ul>
<p>Think: In both of these situations, H being true implies a relationship between <span class="math inline">\(F\)</span> and <span class="math inline">\(G\)</span>. What about when <span class="math inline">\(H\)</span> is not true?</p>
</div>
</section>
<section id="random-variables" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="random-variables"><span class="header-section-number">2.4</span> Random Variables</h2>
<p><em>In Bayesian inference a random variable is defined as an unknown numerical quantity about which we make probability statements.</em> For example, the quantitative outcome of a survey, experiment or study is a random variable before the study is performed. Additionally, a fixed but unknown population parameter is also a random variable</p>
<section id="discrete-ramdon-variables" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="discrete-ramdon-variables"><span class="header-section-number">2.4.1</span> Discrete Ramdon variables</h3>
<p>Let <span class="math inline">\(Y\)</span> be a random variable and let <span class="math inline">\(\mathcal{Y}\)</span> be the set of all possible values that <span class="math inline">\(Y\)</span> can take. If <span class="math inline">\(\mathcal{Y}\)</span> is countable, meaning that <span class="math inline">\(\mathcal{Y} = \{y_1,y_2,\dots\}\)</span>, then <span class="math inline">\(Y\)</span> is a discrete random variable.</p>
<div class="callout-definition" title="Probability mass function">
<p>The event that the outcome <span class="math inline">\(Y\)</span> of our survey has the value <span class="math inline">\(Y\)</span> is expressed as <span class="math inline">\(\{Y=y\}\)</span>. For each <span class="math inline">\(y\in\mathcal{Y}\)</span>, the shorthand notation for <span class="math inline">\(\mathrm{Pr}(Y=y)\)</span> is <span class="math inline">\(p(y)\)</span>, and <span class="math inline">\(p(\cdot)\)</span> is called the <strong>probability mass function</strong> of <span class="math inline">\(Y\)</span>, and with two properties</p>
<ol type="1">
<li><p><span class="math inline">\(0 \leq p(y) \leq 1\)</span> for all <span class="math inline">\(y\in\mathcal{Y}\)</span>,</p></li>
<li><p><span class="math inline">\(\sum_{y\in\mathcal{Y}} p(y) = 1\)</span>.</p></li>
</ol>
</div>
<p>General probability statements about <span class="math inline">\(Y\)</span> can be derived from the pdf/pmf, for example, for any subset <span class="math inline">\(A \subseteq \mathcal{Y}\)</span>, we have <span class="math inline">\(\mathrm{Pr}(Y\in A) = \sum_{y\in A} p(y)\)</span>. When we have two disjoint subsets <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> of <span class="math inline">\(\mathcal{Y}\)</span>, we have <span class="math display">\[\mathrm{Pr}(Y\in A \cup B) = \mathrm{Pr}(Y\in A) + \mathrm{Pr}(Y\in B)=\sum_{y\in A} p(y) + \sum_{y\in B} p(y).\]</span></p>
<div class="callout-example" title="Binomial distribution">
<p>Let <span class="math inline">\(Y\)</span> be the number of successes in <span class="math inline">\(n\)</span> independent Bernoulli trials, each with probability of success <span class="math inline">\(\theta\)</span>. Then, <span class="math inline">\(Y\)</span> follows a Binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(\theta\)</span>, denoted as <span class="math inline">\(Y \sim \mathrm{Binomial}(n,p)\)</span>. The probability mass function of <span class="math inline">\(Y\)</span> is given by <span class="math display">\[
p(y) = \mathrm{Pr}(Y=y) = \binom{n}{y} \theta^y (1-\theta)^{n-y}, \quad y=0,1,2,\dots,n.
\]</span> If <span class="math inline">\(\theta=0.3\)</span> and <span class="math inline">\(n=3\)</span>, then the probability of observing exactly 2 successes is <span class="math display">\[
p(2) = \mathrm{Pr}(Y=2 \mid \theta=0.3) = \binom{3}{2
} (0.3)^2 (0.7)^{1} = 3 \cdot 0.09 \cdot 0.7 = 0.189.
\]</span></p>
</div>
</section>
<section id="continuous-random-variables" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="continuous-random-variables"><span class="header-section-number">2.4.2</span> Continuous random variables</h3>
<p>If <span class="math inline">\(\mathcal{Y}\)</span> is uncountable, for example, <span class="math inline">\(\mathcal{Y} = \mathbb{R}\)</span> or <span class="math inline">\(\mathcal{Y} = (0,1)\)</span>, then <span class="math inline">\(Y\)</span> is a continuous random variable. In this case, we cannot list all possible values of <span class="math inline">\(Y\)</span> and assign probabilities to each value. Instead, we use a probability distribution to describe the distribution of <span class="math inline">\(Y\)</span>. That is, the cummulative distribution function (cdf) defined as follows.</p>
<div class="callout-definition" title="Cummulative distribution function">
<p>The <strong>cumulative distribution function</strong> (cdf) of a continuous random variable <span class="math inline">\(Y\)</span> is defined as <span class="math display">\[
F(y) = \mathrm{Pr}(Y \leq y), \quad y \in \mathcal{Y}.
\]</span></p>
</div>
<p>Note that, for the cdf <span class="math inline">\(F(y)\)</span>, we have the following properties:</p>
<ul>
<li><span class="math inline">\(0 \leq F(y) \leq 1\)</span> for all <span class="math inline">\(y\in\mathcal{Y}\)</span>,</li>
<li><span class="math inline">\(F(y)\)</span> is non-decreasing, meaning that if <span class="math inline">\(y_1 &lt; y_2\)</span>, then <span class="math inline">\(F(y_1) \leq F(y_2)\)</span>,</li>
<li><span class="math inline">\(\lim_{y \to -\infty} F(y) = 0\)</span></li>
<li><span class="math inline">\(\lim_{y \to \infty} F(y) = 1\)</span>.</li>
</ul>
<p>Probability of various events can be derived from the cdf. For example, for any interval <span class="math inline">\(A = (a,b] \subseteq \mathcal{Y}\)</span>, we have <span class="math display">\[
\mathrm{Pr}(Y \in A) = \mathrm{Pr}(a &lt; Y \leq b) =
F(b) - F(a).
\]</span> Also, <span class="math inline">\(\mathrm{Pr}(Y \leq a) = F(a)\)</span> and <span class="math inline">\(\mathrm{Pr}(Y &gt; a) = 1 - F(a)\)</span>.</p>
</section>
<section id="description-of-distributions-through-quantiles-and-moments" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="description-of-distributions-through-quantiles-and-moments"><span class="header-section-number">2.4.3</span> Description of distributions through quantiles and moments</h3>
<p>In this subsection, we discuss a few ways to describe probability distributions: quantiles and moments. They are used to describe the behaviour of the distribution compressing them into summary statistics.</p>
<div class="callout-definition" title="Expectation (Mean)">
<p>The <strong>expectation</strong> or <strong>mean</strong> of a random variable <span class="math inline">\(Y\)</span> can be thought as the centre of mass or the location of the distribution, which is defined as</p>
<ul>
<li>For discrete random variable: <span class="math display">\[
E(Y) = \sum_{y\in\mathcal{Y}} y p(y).
\]</span></li>
<li>For continuous random variable: <span class="math display">\[
E(Y) = \int_{\mathcal{Y}} y f(y) dy.
\]</span></li>
</ul>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Difference between mean, mode and median">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Difference between mean, mode and median
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Mean: the centre of mass of the distribution</p></li>
<li><p>Mode: The most probable value of <span class="math inline">\(Y\)</span></p></li>
<li><p>Median: The value of Y in the middle of the distribution.</p></li>
</ul>
</div>
</div>
<p>In skewed distribution, the three will not equal to each other.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Theoretical reference lines</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>lines_normal <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">value =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">Statistic =</span> <span class="fu">c</span>(<span class="st">"Mean"</span>, <span class="st">"Median"</span>, <span class="st">"Mode"</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>lines_lognormal <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">value =</span> <span class="fu">c</span>(<span class="fu">exp</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">8</span>), <span class="dv">1</span>, <span class="fu">exp</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">4</span>)),</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">Statistic =</span> <span class="fu">c</span>(<span class="st">"Mean"</span>, <span class="st">"Median"</span>, <span class="st">"Mode"</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>cols <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Mean"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Median"</span> <span class="ot">=</span> <span class="st">"darkgreen"</span>, <span class="st">"Mode"</span> <span class="ot">=</span> <span class="st">"purple"</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal distribution</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> lines_normal,</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> value, <span class="at">color =</span> Statistic),</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">linetype =</span> <span class="st">"dashed"</span>,</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">1</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> cols) <span class="sc">+</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>)) <span class="sc">+</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Non-skewed Distribution (Normal)"</span>,</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Density"</span>, <span class="at">color =</span> <span class="st">"Statistic"</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-normal distribution: LN(0, 0.5)</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="co"># -----------------------------</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="at">fun =</span> <span class="cf">function</span>(x) <span class="fu">dlnorm</span>(x, <span class="at">meanlog =</span> <span class="dv">0</span>, <span class="at">sdlog =</span> <span class="fl">0.5</span>),</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">1</span>,</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> lines_lognormal,</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> value, <span class="at">color =</span> Statistic),</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">linetype =</span> <span class="st">"dashed"</span>,</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">1</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> cols) <span class="sc">+</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">8</span>)) <span class="sc">+</span></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Skewed Distribution (Log-normal)"</span>,</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Density"</span>, <span class="at">color =</span> <span class="st">"Statistic"</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>p1</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="02_probability_files/figure-html/3m-comparison-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>p2</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="02_probability_files/figure-html/3m-comparison-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Why use mean?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Why use mean?
</div>
</div>
<div class="callout-body-container callout-body">
<p>The mean is widely used in statistics and data analysis for several reasons:</p>
<ol type="1">
<li><p>Mathematical properties: The mean has desirable mathematical properties, such as linearity, which makes it easier to work with in various statistical analyses and models.</p></li>
<li><p>Sensitivity to all values: The mean takes into account all values in the dataset, providing a comprehensive measure of central tendency. It is also a scaled version of the total, which is often an interest</p></li>
<li><p>Foundation for other statistical measures: The mean serves as the basis for many other statistical measures, such as variance and standard deviation, which are essential for understanding the spread and variability of data.</p></li>
<li><p>Mean minimizes the sum of squared deviations: The mean is the value that minimizes the sum of squared deviations (i.e., the expected penalty by choosing one value) from itself, making it a natural choice for summarizing data.</p></li>
<li><p>May contains full information: In some distributions (e.g., bernoulli distribution), the mean contains all the information about the distribution, making it a sufficient statistic for inference.</p></li>
</ol>
</div>
</div>
<div class="callout-definition" title="Variance and Standard Deviation">
<p>The <strong>variance</strong> of a random variable <span class="math inline">\(Y\)</span> measures the spread or dispersion of the distribution, and is defined as <span class="math display">\[
\mathrm{Var}(Y) = E\left[(Y - E(Y))^2\right] = E[Y^2]- E^2[Y].
\]</span> The standard deviation is the square root of the variance, denoted as <span class="math inline">\(\mathrm{SD}(Y) = \sqrt{\mathrm{Var}(Y)}\)</span>.</p>
</div>
<div class="callout-definition" title="Quantile">
<p>The <strong>quantile</strong> of order <span class="math inline">\(\alpha\)</span> of a random variable <span class="math inline">\(Y\)</span> is defined as the value <span class="math inline">\(y_\alpha\)</span> such that <span class="math display">\[
\mathrm{Pr}(Y \leq y_\alpha) = F(y_\alpha) = \alpha
\]</span> for <span class="math inline">\(0 &lt; \alpha &lt; 1\)</span>.</p>
</div>
<p>For example, the median is the quantile of order 0.5, denoted as <span class="math inline">\(y_{0.5}\)</span>, which satisfies <span class="math inline">\(\mathrm{Pr}(Y \leq y_{0.5}) = 0.5\)</span>. Also, <span class="math inline">\((y_{0.025},y_{0.975})\)</span> and <span class="math inline">\((y_{0.25},y_{0.75})\)</span> contains 95% and 50% of the mass of the distribution, respectively.</p>
</section>
</section>
<section id="joint-disitrubiton" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="joint-disitrubiton"><span class="header-section-number">2.5</span> Joint Disitrubiton</h2>
<section id="discrete-random-variables" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="discrete-random-variables"><span class="header-section-number">2.5.1</span> Discrete random variables</h3>
<p>Let <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> be two random variables with possible values in <span class="math inline">\(\mathcal{Y}_1\)</span> and <span class="math inline">\(\mathcal{Y}_2\)</span>, respectively. The <strong>joint distribution</strong> of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> describes the probability of various combinations of values that <span class="math inline">\((Y_1,Y_2)\)</span> can take.</p>
<p>Joint beliefs about <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> can be represented with probabilities. For example, for subsets <span class="math inline">\(A\subset \mathcal{Y}_1\)</span> and <span class="math inline">\(B\subset \mathcal{Y}_2\)</span>, <span class="math inline">\(\mathrm{Pr}(\{Y_1\in A\} \cap \{Y_2 \in B\})\)</span> represents our belief that <span class="math inline">\(Y_1\)</span> takes a value in <span class="math inline">\(A\)</span> and <span class="math inline">\(Y_2\)</span> takes a value in <span class="math inline">\(B\)</span>. The <em>joint pdf</em> or <em>joint density</em> of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> is defined as</p>
<p><span class="math display">\[
p_{Y_1 Y_2}\left(y_1, y_2\right)=\operatorname{Pr}\left(\left\{Y_1=y_1\right\} \cap\left\{Y_2=y_2\right\}\right), \text { for } y_1 \in \mathcal{Y}_1, y_2 \in \mathcal{Y}_2 .
\]</span></p>
<p>The <em>marginal density</em> of <span class="math inline">\(Y_1\)</span> can be computed from the joint density: <span class="math display">\[
\begin{aligned}
p_{Y_1}\left(y_1\right) &amp; \equiv \operatorname{Pr}\left(Y_1=y_1\right) \\
&amp; =\sum_{y_2 \in \mathcal{Y}_2} \operatorname{Pr}\left(\left\{Y_1=y_1\right\} \cap\left\{Y_2=y_2\right\}\right) \\
&amp; \equiv \sum_{y_2 \in \mathcal{Y}_2} p_{Y_1 Y_2}\left(y_1, y_2\right)
\end{aligned}
\]</span></p>
<p>The <em>conditional density</em> of <span class="math inline">\(Y_2\)</span> given <span class="math inline">\(\{Y_1=y_1\}\)</span> can be computed from the joint density and the marginal density: <span class="math display">\[
\begin{aligned}
p_{Y_2 \mid Y_1}\left(y_2 \mid y_1\right) &amp; =\frac{\operatorname{Pr}\left(\left\{Y_1=y_1\right\} \cap\left\{Y_2=y_2\right\}\right)}{\operatorname{Pr}\left(Y_1=y_1\right)} \\
&amp; =\frac{p_{Y_1 Y_2}\left(y_1, y_2\right)}{p_{Y_1}\left(y_1\right)} .
\end{aligned}
\]</span></p>
<p>You should be able to see that</p>
<ul>
<li><span class="math inline">\(\left\{p_{Y_1}, p_{Y_2 \mid Y_1}\right\}\)</span> can be derived from <span class="math inline">\(p_{Y_1 Y_2}\)</span>,</li>
<li><span class="math inline">\(\left\{p_{Y_2}, p_{Y_1 \mid Y_2}\right\}\)</span> can be derived from <span class="math inline">\(p_{Y_1 Y_2}\)</span></li>
<li><span class="math inline">\(p_{Y_1 Y_2}\)</span> can be derived from <span class="math inline">\(\left\{p_{Y_1}, p_{Y_2 \mid Y_1}\right\}\)</span></li>
<li><span class="math inline">\(p_{Y_1 Y_2}\)</span> can be derived from <span class="math inline">\(\left\{p_{Y_2}, p_{Y_1 \mid
Y_2}\right\}\)</span></li>
</ul>
<p>BUT</p>
<ul>
<li><span class="math inline">\(p_{Y_1 Y_2}\)</span> cannot be derived from <span class="math inline">\(\left\{p_{Y_1}, p_{Y_2}\right\}\)</span>.</li>
</ul>
<p>The subscripts of density functions are often dropped, in which case the type of density function is determined by the arguments. For example,</p>
<ul>
<li><span class="math inline">\(p(y_1,y_2)=p_{Y_1 Y_2}(y_1,y_2)\)</span> is the joint density of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>,</li>
<li><span class="math inline">\(p(y_1)=p_{Y_1}(y_1)\)</span> is the marginal density of <span class="math inline">\(Y_1\)</span></li>
<li><span class="math inline">\(p(y_2 \mid y_1)=p_{Y_2\mid Y_1}(y_2 \mid y_1)\)</span> is the conditional density of <span class="math inline">\(Y_2\)</span> given <span class="math inline">\(\{Y_1=y_1\}\)</span>, and so on.</li>
</ul>
<div class="callout-example" title="Joint distribution of education and income">
<p>Suppose a sociological study reports the following joint distribution of parents’ education level and children’s income level in a population.</p>
<p>Joint distribution of education and income Suppose a sociological study reports the following <strong>joint distribution</strong> of <strong>parents’ education level</strong> and <strong>children’s income level</strong> in a population as shown in the Table below</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Parent \ Child</th>
<th>Low Income</th>
<th>Middle Income</th>
<th>High Income</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>High School or Less</strong></td>
<td>0.18</td>
<td>0.22</td>
<td>0.10</td>
</tr>
<tr class="even">
<td><strong>College</strong></td>
<td>0.08</td>
<td>0.20</td>
<td>0.12</td>
</tr>
<tr class="odd">
<td><strong>Graduate School</strong></td>
<td>0.04</td>
<td>0.06</td>
<td>0.10</td>
</tr>
</tbody>
</table>
<p>Suppose we randomly sample a <strong>parent–child pair</strong> from this population.</p>
<p>Let<br>
- <span class="math inline">\(Y_1\)</span> be the parent’s education level<br>
- <span class="math inline">\(Y_2\)</span> be the child’s income level</p>
<p>We are interested in the conditional probability that the child has <strong>high income</strong>, given that the parent has a <strong>college education</strong>.</p>
<p>We may answer this question using the conditional probability formula:</p>
<p><span class="math display">\[
\Pr(Y_2 = \text{High Income} \mid Y_1 = \text{College})
= \frac{\Pr(Y_2 = \text{High Income} \cap Y_1 = \text{College})}
{\Pr(Y_1 = \text{College})}
\]</span></p>
<p>From the table,</p>
<p><span class="math display">\[
\Pr(Y_2 = \text{High Income} \cap Y_1 = \text{College}) = 0.12
\]</span></p>
<p><span class="math display">\[
\Pr(Y_1 = \text{College}) = 0.08 + 0.20 + 0.12 = 0.40
\]</span></p>
<p>Therefore,</p>
<p><span class="math display">\[
\Pr(Y_2 = \text{High Income} \mid Y_1 = \text{College})
= \frac{0.12}{0.40}
= 0.30
\]</span></p>
<p>Thus, our conclusion from the table is, among children whose parents have a college education, <strong>30%</strong> attain high income.</p>
</div>
</section>
<section id="continuous-random-variables-1" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="continuous-random-variables-1"><span class="header-section-number">2.5.2</span> Continuous random variables</h3>
<p>Let <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> be two continuous random variables with possible values in <span class="math inline">\(\mathcal{Y}_1\)</span> and <span class="math inline">\(\mathcal{Y}_2\)</span>, respectively. The <strong>joint distribution</strong> of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> describes the probability of various combinations of values that <span class="math inline">\((Y_1,Y_2)\)</span> can take. We again work with the cumulative distribution function (cdf). The definition is given as follows.</p>
<div class="callout-definition" title="Joint cumulative distribution function and joint density">
<p>Given a continuous joint cdf <span class="math inline">\(F_{Y_1 Y_2}(y_1,y_2)\)</span>, there is a function <span class="math inline">\(p_{Y_1,Y_2}\)</span> such that <span class="math display">\[
F_{Y_1,Y_2}(a,b) = \int_{-\infty}^a \int_{-\infty}^b p_{Y_1,Y_2}(y_1,y_2) dy_2 dy_1,
\]</span> and <span class="math inline">\(p_{Y_1,Y_2}(y_1,y_2)\)</span> is called the <em>joint density function</em> of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>.</p>
</div>
<p>Similar to the discrete case, we can derive marginal and conditional densities from the joint density as</p>
<ul>
<li><p>Marginal density of <span class="math inline">\(Y_1\)</span>: <span class="math display">\[
p_{Y_1}(y_1) = \int_{\mathcal{Y}_2} p_{Y_1,Y_2}(y_1,y_2) dy_2,
\]</span></p></li>
<li><p>Conditional density of <span class="math inline">\(Y_2\)</span> given <span class="math inline">\(\{Y_1=y_1\}\)</span>: <span class="math display">\[
p_{Y_2 \mid Y_1}(y_2 \mid y_1) = \frac{p_{Y_1,Y_2}(y_1,y_2)}{p_{Y_1}(y_1)}.
\]</span></p></li>
</ul>
<p>Think about why <span class="math inline">\(p_{Y_2 \mid Y_1}(y_2 \mid y_1)\)</span> is an actual pdf.</p>
</section>
<section id="mixed-continuous-and-discrete-variables" class="level3" data-number="2.5.3">
<h3 data-number="2.5.3" class="anchored" data-anchor-id="mixed-continuous-and-discrete-variables"><span class="header-section-number">2.5.3</span> Mixed continuous and discrete variables</h3>
<p>It is possible to have joint distributions involving both discrete and continuous random variables. For example, let <span class="math inline">\(Y_1\)</span> be a discrete random variable taking values in <span class="math inline">\(\mathcal{Y}_1\)</span> and <span class="math inline">\(Y_2\)</span> be a continuous random variable taking values in <span class="math inline">\(\mathcal{Y}_2\)</span>. The joint distribution of <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> can be described by the joint density function <span class="math inline">\(p_{Y_1,Y_2}(y_1,y_2)\)</span>, which gives the probability that <span class="math inline">\(Y_1\)</span> takes the value <span class="math inline">\(y_1\)</span> and <span class="math inline">\(Y_2\)</span> takes a value in an infinitesimal interval around <span class="math inline">\(y_2\)</span>. One such as example is that <span class="math inline">\(Y_1\)</span> is a binary variable indicating the presence or absence of a disease, and <span class="math inline">\(Y_2\)</span> is a continuous variable representing the severity of symptoms. Suppose we define</p>
<ul>
<li>Marginal density <span class="math inline">\(p_{Y_1}\)</span> from our belief <span class="math inline">\(\mathrm{Pr}(Y_1=y_1)\)</span></li>
<li>a conditional density <span class="math inline">\(p_{Y_2\mid Y_1}\)</span> from <span class="math inline">\(\mathrm{Pr}(Y_2\le y_2\mid Y_1=y_1)\doteq F_{Y_2\mid Y_1}(y_2\mid y_1)\)</span>.</li>
</ul>
<p>Then, the joint density can be derived as <span class="math display">\[
p_{Y_1,Y_2}(y_1,y_2) = p_{Y_1}(y_1) p_{Y_2 \mid Y_1}(y_2 \mid y_1),
\]</span> and the probability can be calculated as <span class="math display">\[
\mathrm{Pr}(Y_1\in A,Y_2\in B) = \int_{y_2\in B} \left\{\sum_{y_1\in A}p_{Y_1,Y_2}(y_1,y_2)\right\}dy_2.
\]</span></p>
</section>
<section id="bayes-rule-and-parameter-estimation" class="level3" data-number="2.5.4">
<h3 data-number="2.5.4" class="anchored" data-anchor-id="bayes-rule-and-parameter-estimation"><span class="header-section-number">2.5.4</span> Bayes’ rule and parameter estimation</h3>
<p>Let</p>
<ul>
<li><p><span class="math inline">\(\theta\)</span>: proportion of people in a large population who have a certain charactersitic.</p></li>
<li><p><span class="math inline">\(Y\)</span>: number of people in a small random sample from the population who have the charactersitic</p></li>
</ul>
<p>Then, in this case, we may threat <span class="math inline">\(\theta\)</span> as continuous random variable taking values in <span class="math inline">\(\Theta = (0,1)\)</span>, and <span class="math inline">\(Y\)</span> as a discrete random variable taking values in <span class="math inline">\(\mathcal{Y}= \{0,1,2,\dots,n\}\)</span>, where <span class="math inline">\(n\)</span> is the sample size. <em>Bayesian estimation of the parameter</em> <span class="math inline">\(\theta\)</span> derives from the calculate of <span class="math inline">\(p(\theta\mid y)\)</span> where <span class="math inline">\(y\)</span> is the observed value of <span class="math inline">\(Y\)</span>. In Bayesian, this calculation first requires that we have a joint density <span class="math inline">\(p(y,\theta)\)</span> representing our belief about <span class="math inline">\(\theta\)</span> and the survey outcome <span class="math inline">\(Y\)</span>. Often, it is natural to construct this joint density from</p>
<ul>
<li><span class="math inline">\(p(\theta)\)</span>: our prior belief about <span class="math inline">\(\theta\)</span> before seeing the data, and</li>
<li><span class="math inline">\(p(y \mid \theta)\)</span>: belief about <span class="math inline">\(Y\)</span> given <span class="math inline">\(\theta\)</span>, often called the likelihood function.</li>
</ul>
<p>Once we observed <span class="math inline">\(\{Y=y\}\)</span>, we need to compute our updated belief about <span class="math inline">\(\theta\)</span>, represented by the <strong>posterior density</strong> <span class="math inline">\(p(\theta \mid y)\)</span> as <span class="math display">\[
p(\theta \mid y) = \frac{p(\theta,y)}{p(y)} = \frac{p(y \mid \theta) p(\theta)}{p(y)} = \frac{p(y \mid \theta) p(\theta)}{\int_{\Theta} p(y \mid \theta) p(\theta) d\theta}.
\]</span></p>
<p>If we have two values <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span> in <span class="math inline">\(\Theta\)</span> that may be true, then the ratio of their posterior densities is given by</p>
<p><span class="math display">\[
\frac{p(\theta_1 \mid y)}{p(\theta_2 \mid y)} = \frac{p(y \mid \theta_1) p(\theta_1) / p(y)}{p(y \mid \theta_2) p(\theta_2) / p(y)} =
\frac{p(y \mid \theta_1) p(\theta_1)}{p(y \mid \theta_2) p(\theta_2)}.
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="Note">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>From this calculation, we notice when we are calculating the relative posterior probability between two parameter values <strong>we do not need</strong> calculate <span class="math inline">\(p(y)\)</span> out.</p>
</div>
</div>
<p>Another way to think about this is, for a function of <span class="math inline">\(\theta\)</span>, <span class="math display">\[
p(\theta \mid y) \propto p(y \mid \theta) p(\theta).
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="Note">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We will see that the numerator is the important part, while the denominator is just a normalizing constant to make sure the posterior density integrates to 1.</p>
</div>
</div>
</section>
</section>
<section id="independence-random-variables" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="independence-random-variables"><span class="header-section-number">2.6</span> Independence Random Variables</h2>
<p>Let <span class="math inline">\(Y_1,\dots,Y_n\)</span> be random variables with joint density <span class="math inline">\(p(y_1,\dots,y_n)\)</span>, and <span class="math inline">\(\theta\)</span> is the parameter describe the conditions under which the random variables are generated. We say that <span class="math inline">\(Y_1,\dots,Y_n\)</span> are conditionally independent given <span class="math inline">\(\theta\)</span> if every collection of <span class="math inline">\(n\)</span> sets <span class="math inline">\(\{A_1,\dots,A_n\}\)</span> satisfies <span class="math display">\[
\mathrm{Pr}(Y_1 \in A_1,\dots,Y_n \in A_n \mid \theta) = \prod_{i=1}^n \mathrm{Pr}(Y_i \in A_i \mid \theta).
\]</span> If we have independence property, then <span class="math display">\[
\mathrm{Pr}(Y_i\in A_i \mid \theta, Y_j\in A_j) = \mathrm{Pr}(Y_i \in A_i \mid \theta),
\]</span> so the conditional indpenddence can be interpreted as meaning that <span class="math inline">\(Y_j\)</span> gives no additional information about <span class="math inline">\(Y_i\)</span> once we know <span class="math inline">\(\theta\)</span>. Also, under independence, the joint density can be factorized as <span class="math display">\[
p(y_1,\dots,y_n \mid \theta) = \prod_{i= 1}^n p_{Y_i}(y_i \mid \theta).
\]</span></p>
<p>If the samples are also identically distributed, meaning that each <span class="math inline">\(Y_i\)</span> has the same marginal density <span class="math inline">\(p_Y(y \mid \theta)\)</span>, then the joint density can be further simplified as <span class="math display">\[
p(y_1,\dots,y_n \mid \theta) = \prod_{i= 1}^n p_Y(y_i \mid \theta).
\]</span></p>
<p>In this case , we say that <span class="math inline">\(Y_1,\dots,Y_n\)</span> are <strong>independent and identically distributed</strong> (i.i.d.) given <span class="math inline">\(\theta\)</span>, with notation <span class="math display">\[  
Y_1,\dots,Y_n\mid \theta \stackrel{i.i.d.}{\sim} p_Y(y \mid \theta).
\]</span></p>
</section>
<section id="exchangeability" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="exchangeability"><span class="header-section-number">2.7</span> Exchangeability</h2>
<div class="callout-definition" title="Exchangeability">
<p>A sequence of random variables <span class="math inline">\(Y_1,Y_2,\dots,Y_n\)</span> is <strong>exchangeable</strong> if for any permutation <span class="math inline">\(\pi\)</span> of the indices <span class="math inline">\(\{1,2,\dots ,n\}\)</span>, we have <span class="math display">\[
p(y_1,y_2,\dots,y_n) = p(y_{\pi(1 )},y_{\pi(2)},\dots,y_{\pi(n)}).
\]</span></p>
</div>
<p>In other words, the joint density of an exchangeable sequence is invariant to the order of the random variables. That is, the labels contains no information about the outcome.</p>
<div class="callout-example" title="Defective Items in a Production Batch">
<p>Suppose a factory produces a large batch of items. Each item may be either <strong>defective</strong> or <strong>non-defective</strong>.</p>
<p>Let <span class="math display">\[
Y_i =
\begin{cases}
1, &amp; \text{if the } i\text{th inspected item is defective}, \\
0, &amp; \text{otherwise}.
\end{cases}
\]</span></p>
<p>We inspect <span class="math inline">\(n = 10\)</span> items chosen at random from the batch and record<br>
<span class="math inline">\(Y_1, Y_2, \dots, Y_{10}.\)</span></p>
<p>Consider the following three observed sequences:</p>
<ol type="1">
<li><span class="math inline">\(p(1,0,1,0,1,0,0,1,0,1)\)</span></li>
<li><span class="math inline">\(p(0,1,0,1,0,1,1,0,0,1)\)</span></li>
<li><span class="math inline">\(p(1,1,0,0,1,0,1,0,0,1)\)</span></li>
</ol>
<p>Each sequence contains <strong>5 defective items</strong> and <strong>5 non-defective items</strong>.</p>
<p>Question: Is there a reason to assign these three sequences <em>different probabilities</em>?</p>
<p>If the inspection order conveys no additional information about quality, then <em>only the number of defective items matters</em>, not their positions in the sequence. This motivates the concept of exchangeability.</p>
</div>
<section id="independence-versus-dependence" class="level3" data-number="2.7.1">
<h3 data-number="2.7.1" class="anchored" data-anchor-id="independence-versus-dependence"><span class="header-section-number">2.7.1</span> Independence versus dependence</h3>
<p>Consider the probability assignments</p>
<p><span class="math display">\[
\begin{cases}
\Pr(Y_{10} = 1) = a, \\[6pt]
\Pr(Y_{10} = 1 \mid Y_1 = \cdots = Y_9 = 1) = b.
\end{cases}
\]</span></p>
<p>If <span class="math inline">\(a \neq b\)</span>, then <span class="math inline">\(Y_{10}\)</span> is <strong>not independent</strong> of <span class="math inline">\(Y_1, \dots, Y_9\)</span>.</p>
<p>However, lack of independence does <strong>not</strong> imply lack of exchangeability.</p>
<p>Question: should we have <span class="math inline">\(a = b\)</span>, <span class="math inline">\(a &gt; b\)</span> or <span class="math inline">\(a  &lt; b\)</span>?</p>
</section>
<section id="a-latent-parameter-model" class="level3" data-number="2.7.2">
<h3 data-number="2.7.2" class="anchored" data-anchor-id="a-latent-parameter-model"><span class="header-section-number">2.7.2</span> A latent-parameter model</h3>
<p>Suppose the defect rate <span class="math inline">\(\theta\)</span> of the factory is unknown.</p>
<p>Conditional on <span class="math inline">\(\theta\)</span>, <span class="math display">\[
Y_1, \dots, Y_{10} \mid \theta \sim \text{i.i.d. Bernoulli}(\theta).
\]</span></p>
<p>Then <span class="math display">\[
\Pr(Y_1 = y_1, \dots, Y_{10} = y_{10} \mid \theta)
= \theta^{\sum y_i}(1-\theta)^{10-\sum y_i}.
\]</span></p>
<p>If our uncertainty about <span class="math inline">\(\theta\)</span> is described by a prior distribution <span class="math inline">\(p(\theta)\)</span>, the marginal joint distribution is</p>
<p><span class="math display">\[
p(y_1, \dots, y_{10})
= \int \theta^{\sum y_i}(1-\theta)^{10-\sum y_i} p(\theta)\, d\theta.
\]</span></p>
<p>This probability depends <strong>only on the number of defective items</strong>, not their order.</p>
<p>Thus, we have exchangeability, even though the <span class="math inline">\(Y_i\)</span> are not independent under this model of belief.</p>
<div class="callout-theorem">
<p><strong>Conditional i.i.d. given a latent parameter implies marginal exchangeability.</strong> That is, if <span class="math inline">\(\theta \sim p(\theta)\)</span> and <span class="math inline">\(Y_1,\dots,Y_n\)</span> are conditionally i.i.d. given <span class="math inline">\(\theta\)</span>, then <span class="math inline">\(Y_1,\dots,Y_n\)</span> (i.e., unconditional on <span class="math inline">\(\theta\)</span>) are exchangeable.</p>
</div>
<p>For the Proof, see page 28 in Hopf (2009).</p>
</section>
</section>
<section id="de-finettis-theorem" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="de-finettis-theorem"><span class="header-section-number">2.8</span> de Finetti’s Theorem</h2>
<p>As of now, we have seen that conditional i.i.d. given a latent parameter implies marginal exchangeability. For example, <span class="math display">\[
\begin{cases}
Y_1,\dots,Y_n \mid \theta \stackrel{i.i.d.}{\sim}  \\
\theta \sim p(\theta) \end{cases} \implies Y_1,\dots,Y_n \text{ are exchangeable}.
\]</span></p>
<p>The converse is also true, as stated in de Finetti’s theorem.</p>
<div class="callout-theorem" title="de Finetti's Theorem">
<p>Let <span class="math inline">\(Y_i\in\mathcal{Y}\)</span> for all <span class="math inline">\(i \in\{1,2,\dots,n\}\)</span> be an exchangeable sequence of random variables. Then, there exists a parameter space <span class="math inline">\(\Theta\)</span> and a prior distribution <span class="math inline">\(p(\theta)\)</span> on <span class="math inline">\(\Theta\)</span> such that the joint distribution of <span class="math inline">\(Y_1,\dots,Y_n\)</span> can be represented as <span class="math display">\[
p(y_1,\dots,y_n) = \int_{\Theta} \left\{\prod_{i=1}^n p_Y(y_i \mid \theta)\right\} p(\theta) d\theta,
\]</span> where <span class="math inline">\(p_Y(y \mid \theta)\)</span> is a probability density function on <span class="math inline">\(\mathcal{Y}\)</span> for each <span class="math inline">\(\theta \in \Theta\)</span>. The prior and sampling model depend on the form of the belief model <span class="math inline">\(p(y_1,\dots,y_n)\)</span>.</p>
</div>
<p>The probability distribution <span class="math inline">\(p(\theta)\)</span> represents our belief about the outcomes <span class="math inline">\(\{Y_1,Y_2,\dots,Y_n\}\)</span>, induced by our belief model <span class="math inline">\(p(y_1,\dots,y_n)\)</span>. That is,</p>
<ul>
<li><span class="math inline">\(p(\theta)\)</span> represents our belief about <span class="math inline">\(\lim_{n\to\infty} \sum Y_i/n\)</span> in the binary sense</li>
<li><span class="math inline">\(p(\theta)\)</span> represents our belief about <span class="math inline">\(\lim_{n\to\infty} \sum (Y_i\le c)/n\)</span> for each <span class="math inline">\(c\)</span> in the general case.</li>
</ul>
<p>The main idea of this and the previous section is as follows <span class="math display">\[
\begin{aligned}
Y_1, \ldots, Y_n \mid \theta &amp;\stackrel{\text{i.i.d.}}{\sim} p(\cdot \mid \theta), \\
\theta &amp;\sim p(\theta)
\end{aligned}
\quad \Longleftrightarrow \quad
Y_1, \ldots, Y_n \text{ are exchangeable for all } n .
\]</span></p>
<p>Question: When is the condition of “exchangeability for all <span class="math inline">\(n\)</span>” reasonable?</p>
<ul>
<li>Have exchaneability and repeatability
<ul>
<li>Exchangeability holds if the labels convey no information</li>
<li>repeatability hold includes the follows
<ol type="1">
<li><span class="math inline">\(Y_1,\dots,Y_n\)</span> are outcomes of a repeartable experiment</li>
<li><span class="math inline">\(Y_1,\dots,Y_n\)</span> are sampled from a finite population <strong>with replacement</strong></li>
<li><span class="math inline">\(Y_1,\dots,Y_n\)</span> are sampled from an infinite population without replacement.</li>
</ol></li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="In large finite population">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>In large finite population
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note, if <span class="math inline">\(Y_1,\dots,Y_n\)</span> are exchangeable and sampled from a finite population of size <span class="math inline">\(N\)</span> that is way bigger than <span class="math inline">\(n\)</span> without replacement, then they can be modelled as <em>approximate</em> being conditional i.i.d.</p>
</div>
</div>
<hr>
<p>This Chapter follows closely with Chapter 2 in Hoff (2009).</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01_intro.html" class="pagination-link" aria-label="Quick Overview">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Quick Overview</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03_bi-1par.html" class="pagination-link" aria-label="Bayesian Inference for single parameter models">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Inference for single parameter models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>