<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Monte Carlo Method and its variations – STAT8310 - Bayesian Data Analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./03_bi-1par.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="custom-callouts.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">STAT8310 - Bayesian Data Analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/chikuang/Teaching-Stat8310"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="././STAT8310---Bayesian-Data-Analysis.pdf"> <i class="bi bi-file-pdf" role="img" aria-label="Download PDF">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./04_MC.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Monte Carlo Method and its variations</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Quick Overview</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Belief function and Probability Review</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_bi-1par.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Inference for single parameter models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_MC.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Monte Carlo Method and its variations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendix</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./App_A-intro-R.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Appendix: Introduction to R</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#background-and-motivation" id="toc-background-and-motivation" class="nav-link active" data-scroll-target="#background-and-motivation"><span class="header-section-number">4.1</span> Background and Motivation</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview"><span class="header-section-number">4.2</span> Overview</a>
  <ul class="collapse">
  <li><a href="#monte-carlo-mc" id="toc-monte-carlo-mc" class="nav-link" data-scroll-target="#monte-carlo-mc"><span class="header-section-number">4.2.1</span> Monte Carlo (MC)</a></li>
  <li><a href="#markov-chain-monte-carlo-mcmc" id="toc-markov-chain-monte-carlo-mcmc" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-mcmc"><span class="header-section-number">4.2.2</span> Markov Chain Monte Carlo (MCMC)</a></li>
  <li><a href="#gibbs-sampler" id="toc-gibbs-sampler" class="nav-link" data-scroll-target="#gibbs-sampler"><span class="header-section-number">4.2.3</span> Gibbs Sampler</a></li>
  <li><a href="#relationship-between-monte-carlo-mcmc-and-gibbs-sampling" id="toc-relationship-between-monte-carlo-mcmc-and-gibbs-sampling" class="nav-link" data-scroll-target="#relationship-between-monte-carlo-mcmc-and-gibbs-sampling"><span class="header-section-number">4.2.4</span> Relationship Between Monte Carlo, MCMC, and Gibbs Sampling</a></li>
  <li><a href="#summary-table" id="toc-summary-table" class="nav-link" data-scroll-target="#summary-table"><span class="header-section-number">4.2.5</span> Summary Table</a></li>
  </ul></li>
  <li><a href="#monte-carlo-methods" id="toc-monte-carlo-methods" class="nav-link" data-scroll-target="#monte-carlo-methods"><span class="header-section-number">4.3</span> Monte Carlo Methods</a></li>
  <li><a href="#the-monte-carlo-method" id="toc-the-monte-carlo-method" class="nav-link" data-scroll-target="#the-monte-carlo-method"><span class="header-section-number">4.4</span> The Monte Carlo Method</a>
  <ul class="collapse">
  <li><a href="#mc-approximation" id="toc-mc-approximation" class="nav-link" data-scroll-target="#mc-approximation"><span class="header-section-number">4.4.1</span> MC Approximation</a></li>
  <li><a href="#convergence-properties" id="toc-convergence-properties" class="nav-link" data-scroll-target="#convergence-properties"><span class="header-section-number">4.4.2</span> Convergence Properties</a></li>
  </ul></li>
  <li><a href="#numerical-evaluation" id="toc-numerical-evaluation" class="nav-link" data-scroll-target="#numerical-evaluation"><span class="header-section-number">4.5</span> Numerical Evaluation</a>
  <ul class="collapse">
  <li><a href="#there-are-much-more-about-the-mc-method" id="toc-there-are-much-more-about-the-mc-method" class="nav-link" data-scroll-target="#there-are-much-more-about-the-mc-method"><span class="header-section-number">4.5.2</span> There are much more about the MC method</a></li>
  <li><a href="#mc-for-predictive-distribution" id="toc-mc-for-predictive-distribution" class="nav-link" data-scroll-target="#mc-for-predictive-distribution"><span class="header-section-number">4.5.3</span> MC for predictive distribution</a></li>
  </ul></li>
  <li><a href="#sampling-from-predictive-distributions" id="toc-sampling-from-predictive-distributions" class="nav-link" data-scroll-target="#sampling-from-predictive-distributions"><span class="header-section-number">4.6</span> 4.3 Sampling from Predictive Distributions</a>
  <ul class="collapse">
  <li><a href="#sampling-model-vs-predictive-model" id="toc-sampling-model-vs-predictive-model" class="nav-link" data-scroll-target="#sampling-model-vs-predictive-model"><span class="header-section-number">4.6.1</span> Sampling Model vs Predictive Model</a></li>
  <li><a href="#prior-predictive-distribution" id="toc-prior-predictive-distribution" class="nav-link" data-scroll-target="#prior-predictive-distribution"><span class="header-section-number">4.6.2</span> Prior Predictive Distribution</a></li>
  <li><a href="#posterior-predictive-distribution" id="toc-posterior-predictive-distribution" class="nav-link" data-scroll-target="#posterior-predictive-distribution"><span class="header-section-number">4.6.3</span> Posterior Predictive Distribution</a></li>
  <li><a href="#monte-carlo-sampling-from-the-posterior-predictive-distribution" id="toc-monte-carlo-sampling-from-the-posterior-predictive-distribution" class="nav-link" data-scroll-target="#monte-carlo-sampling-from-the-posterior-predictive-distribution"><span class="header-section-number">4.6.4</span> Monte Carlo Sampling from the Posterior Predictive Distribution</a></li>
  <li><a href="#example-comparing-two-groups-poisson-model" id="toc-example-comparing-two-groups-poisson-model" class="nav-link" data-scroll-target="#example-comparing-two-groups-poisson-model"><span class="header-section-number">4.6.5</span> Example: Comparing Two Groups (Poisson Model)</a></li>
  <li><a href="#monte-carlo-approximation-of-predictive-quantities" id="toc-monte-carlo-approximation-of-predictive-quantities" class="nav-link" data-scroll-target="#monte-carlo-approximation-of-predictive-quantities"><span class="header-section-number">4.6.6</span> Monte Carlo Approximation of Predictive Quantities</a></li>
  <li><a href="#checking" id="toc-checking" class="nav-link" data-scroll-target="#checking"><span class="header-section-number">4.6.7</span> Checking</a></li>
  </ul></li>
  <li><a href="#markov-chain-monte-carlo-mcmc-1" id="toc-markov-chain-monte-carlo-mcmc-1" class="nav-link" data-scroll-target="#markov-chain-monte-carlo-mcmc-1"><span class="header-section-number">4.7</span> Markov Chain Monte Carlo (MCMC)</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Monte Carlo Method and its variations</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>Leading objectives:</p>
<ul>
<li>understand how Monte Carlo (MC) and Markov chain Monte Carlo (MCMC) methods differ</li>
<li>implement a Metropolis–Hastings algorithm to draw samples from the posterior</li>
<li>use output of MCMC to obtain estimates and standard errors</li>
<li>use efficient proposals and tuning for MCMC</li>
</ul>
</blockquote>
<section id="background-and-motivation" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="background-and-motivation"><span class="header-section-number">4.1</span> Background and Motivation</h2>
<p>What we have seen in the last chapter up to now, is to use the <code>conjugate prior</code> to obtain closed form expressions for the posterior distribution. However, in many cases, conjugate priors are not available or not desirable. In such cases, we need to resort to numerical methods to approximate the posterior distribution.</p>
<blockquote class="blockquote">
<p><strong>Question.</strong><br>
How can we perform Bayesian inference when conjugate priors are not available and the posterior has no closed-form expression?</p>
</blockquote>
<p>There are two broad classes of approaches:</p>
<ul>
<li><p><strong>Simulation-based methods</strong>:<br>
accept–reject sampling, Markov chain Monte Carlo (MCMC), particle filters, and related algorithms.</p></li>
<li><p><strong>Deterministic approximation methods</strong>:<br>
Laplace approximations (including INLA), variational Bayes, expectation propagation, and related techniques.</p></li>
</ul>
<p>We will be focusing on the Monte Carlo (MC) methods and its variation.</p>
</section>
<section id="overview" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="overview"><span class="header-section-number">4.2</span> Overview</h2>
<section id="monte-carlo-mc" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="monte-carlo-mc"><span class="header-section-number">4.2.1</span> Monte Carlo (MC)</h3>
<p>Monte Carlo methods approximate expectations or probabilities using <strong>random sampling</strong>.<br>
If samples can be drawn <strong>directly</strong> from the target distribution, Monte Carlo methods provide simple and effective estimators.</p>
<p>Typical use: - Numerical integration - Bootstrap methods - Simulation-based probability estimation</p>
</section>
<section id="markov-chain-monte-carlo-mcmc" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="markov-chain-monte-carlo-mcmc"><span class="header-section-number">4.2.2</span> Markov Chain Monte Carlo (MCMC)</h3>
<p>MCMC methods are used when <strong>direct sampling is infeasible</strong>.<br>
They construct a <strong>Markov chain</strong> whose stationary distribution is the target distribution, and use dependent samples from the chain after burn-in.</p>
<p>Typical use: - Bayesian posterior sampling - High-dimensional or unnormalized distributions</p>
</section>
<section id="gibbs-sampler" class="level3" data-number="4.2.3">
<h3 data-number="4.2.3" class="anchored" data-anchor-id="gibbs-sampler"><span class="header-section-number">4.2.3</span> Gibbs Sampler</h3>
<p>The Gibbs sampler is a <strong>special case of MCMC</strong> that samples sequentially from <strong>full conditional distributions</strong>.<br>
Because proposals are drawn exactly from conditionals, all updates are automatically accepted.</p>
<p>Typical use: - Bayesian hierarchical models - Models with conjugate full conditionals</p>
</section>
<section id="relationship-between-monte-carlo-mcmc-and-gibbs-sampling" class="level3" data-number="4.2.4">
<h3 data-number="4.2.4" class="anchored" data-anchor-id="relationship-between-monte-carlo-mcmc-and-gibbs-sampling"><span class="header-section-number">4.2.4</span> Relationship Between Monte Carlo, MCMC, and Gibbs Sampling</h3>
<p>These three concepts are <strong>not competing methods</strong>, but rather form a <strong>nested hierarchy</strong> of ideas used for approximating expectations and probability distributions using randomness.</p>
<p><img src="fig/MC/mc_mcmc_gs.png" class="img-fluid"></p>
</section>
<section id="summary-table" class="level3" data-number="4.2.5">
<h3 data-number="4.2.5" class="anchored" data-anchor-id="summary-table"><span class="header-section-number">4.2.5</span> Summary Table</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 23%">
<col style="width: 22%">
<col style="width: 23%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Method</th>
<th>Independent Samples</th>
<th>Uses Markov Chain</th>
<th>Accept–Reject Step</th>
<th>Typical Application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Monte Carlo (MC)</td>
<td>Yes</td>
<td>No</td>
<td>No</td>
<td>Direct simulation, integration</td>
</tr>
<tr class="even">
<td>MCMC</td>
<td>No</td>
<td>Yes</td>
<td>Usually</td>
<td>Bayesian posterior sampling</td>
</tr>
<tr class="odd">
<td>Gibbs Sampler</td>
<td>No</td>
<td>Yes</td>
<td>No (always accept)</td>
<td>Bayesian models with tractable conditionals</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-note callout-titled" title="Key summary">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Key summary
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Monte Carlo</strong> is the general idea of using randomness for approximation.</li>
<li><strong>MCMC</strong> is Monte Carlo with dependent samples generated by a Markov chain.</li>
<li><strong>Gibbs sampling</strong> is a specific MCMC algorithm based on full conditional distributions.</li>
</ul>
</div>
</div>
</section>
</section>
<section id="monte-carlo-methods" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="monte-carlo-methods"><span class="header-section-number">4.3</span> Monte Carlo Methods</h2>
<p><strong>Motivation: why Monte Carlo?</strong></p>
<p>In Bayesian inference we repeatedly encounter integrals such as</p>
<p><span class="math display">\[
\mathbb{E}[g(\theta)\mid y]
=\int g(\theta)\,p(\theta\mid y)\,d\theta,
\qquad
\Pr(\theta\in A\mid y)=\int_A p(\theta\mid y)\,d\theta,
\]</span></p>
<p>that are not available in closed form. <strong>Monte Carlo</strong> replaces these integrals by averages of random draws.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Key idea: replace an intractable integral by an empirical mean.</p>
</div>
</div>
</section>
<section id="the-monte-carlo-method" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="the-monte-carlo-method"><span class="header-section-number">4.4</span> The Monte Carlo Method</h2>
<p>In the previous chapter, we obtained the following posterior distributions for the birth rates of women without and with bachelor’s degrees:</p>
<p><span class="math display">\[
\theta_1 \mid \sum_{i=1}^{111} Y_{i,1} = 217
\sim \text{Gamma}(219, 112),
\]</span></p>
<p><span class="math display">\[
\theta_2 \mid \sum_{i=1}^{44} Y_{i,2} = 66
\sim \text{Gamma}(68, 45).
\]</span></p>
<p>It was claimed that</p>
<blockquote class="blockquote">
<p><span class="math display">\[
\Pr(\theta_1 &gt; \theta_2 \mid \text{data}) = 0.97.
\]</span></p>
</blockquote>
<p>How do we compute such a probability? From Chapter 2, since <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span> are conditionally independent given the data <span class="math inline">\(y\)</span>, we have <span class="math display">\[
\Pr(\theta_1 &gt; \theta_2 \mid y)
=
\int_0^\infty \int_0^{\theta_1}
p(\theta_1 \mid y)
p(\theta_2 \mid y)
\, d\theta_2 \, d\theta_1.
\]</span></p>
<p>Substituting the gamma densities gives</p>
<p><span class="math display">\[
\int_0^\infty \int_0^{\theta_1}
\text{dgamma}(\theta_1; 219, 112)
\,
\text{dgamma}(\theta_2; 68, 45)
\, d\theta_2 \, d\theta_1.
\]</span></p>
<p>This integral can be evaluated numerically. However, in realistic Bayesian models, such integrals quickly become high-dimensional and analytically intractable. This motivates <strong>Monte Carlo (MC) methods</strong>.</p>
<section id="mc-approximation" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="mc-approximation"><span class="header-section-number">4.4.1</span> MC Approximation</h3>
<p>Suppose we wish to compute</p>
<p><span class="math display">\[
\mathbb{E}[g(\theta) \mid y]
=
\int g(\theta) \, p(\theta \mid y) \, d\theta.
\]</span></p>
<p>If we can generate independent samples</p>
<p><span class="math display">\[
\theta^{(1)}, \ldots, \theta^{(S)}
\sim p(\theta \mid y),
\]</span></p>
<p>then we approximate the expectation by</p>
<p><span class="math display">\[
\frac{1}{S}
\sum_{s=1}^S g(\theta^{(s)}).
\]</span></p>
<p>This is called a <strong>Monte Carlo approximation</strong>. By the Law of Large Numbers,</p>
<p><span class="math display">\[
\frac{1}{S}
\sum_{s=1}^S g(\theta^{(s)})
\;\longrightarrow\;
\mathbb{E}[g(\theta) \mid y] = \int g(\theta) p(\theta \mid y) d\theta
\quad \text{as } S \to \infty.
\]</span> With the property above, we can calculate many quantities of interest about the posterior distribution. For example, suppose <span class="math inline">\(\bar{\theta}\)</span> is the average of <span class="math inline">\(\{\theta^{(1)}, \dots, \theta^{(S)}\}\)</span>, then as <span class="math inline">\(S \to \infty\)</span>:</p>
<ul>
<li><span class="math inline">\(\bar{\theta} \to \mathbb{E}[\theta \mid y]\)</span>,</li>
<li><span class="math inline">\(\frac{1}{S-1}\sum_{s=1}^S (\theta^{(s)} - \bar{\theta})^2\to \mathrm{Var}(\theta \mid y)\)</span>.</li>
<li><span class="math inline">\(\frac{1}{S}\sum_{s=1}^S \mathbf{1}\{\theta^{(s)} \in A\}\to \Pr(\theta \in A \mid y)\)</span>.</li>
<li>the empirical distribution of <span class="math inline">\(\{\theta^{(1)}, \dots, \theta^{(S)}\}\)</span> converges to <span class="math inline">\(p(\theta \mid y)\)</span>.</li>
<li>the sample median converges to the posterior median <span class="math inline">\(\theta_{1/2}\)</span>.</li>
<li>the sample <span class="math inline">\(\alpha\)</span>-quantile converges to <span class="math inline">\(\theta_\alpha\)</span>.</li>
</ul>
</section>
<section id="convergence-properties" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="convergence-properties"><span class="header-section-number">4.4.2</span> Convergence Properties</h3>
<p>Let <span class="math inline">\(\theta^{(1)}, \dots, \theta^{(S)} \sim p(\theta \mid y)\)</span>.</p>
<p>As <span class="math inline">\(S \to \infty\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\displaystyle \frac{\#\{\theta^{(s)} \le c\}}{S}
\;\longrightarrow\;
\Pr(\theta \le c \mid y)\)</span></p></li>
<li><p>The empirical distribution of <span class="math inline">\(\{\theta^{(1)},\dots,\theta^{(S)}\}\)</span> converges to <span class="math inline">\(p(\theta \mid y)\)</span></p></li>
<li><p>The sample median converges to the posterior median <span class="math inline">\(\theta_{1/2}\)</span></p></li>
<li><p>The sample <span class="math inline">\(\alpha\)</span>-quantile converges to <span class="math inline">\(\theta_\alpha\)</span></p></li>
</ul>
<p><strong>Key message:</strong><br>
Almost any aspect of a posterior distribution can be approximated arbitrarily well using a sufficiently large Monte Carlo sample.</p>
<p>Thus Monte Carlo sampling allows us to approximate:</p>
<ul>
<li>posterior means,</li>
<li>posterior variances,</li>
<li>posterior probabilities,</li>
<li>credible intervals,</li>
<li>many more</li>
</ul>
<div class="callout-example" title="(Cont) Estimating probability of  theta1 > theta2">
<p>To approximate <span class="math display">\[
\Pr(\theta_1 &gt; \theta_2 \mid y),
\]</span></p>
<p>we can:</p>
<ol start="0" type="1">
<li>Choose a (large) number of samples <span class="math inline">\(S\)</span> (e.g., <span class="math inline">\(S=10,000\)</span>).</li>
<li>Draw <span class="math inline">\(\theta_1^{(s)} \sim \text{Gamma}(219, 112)\)</span>.</li>
<li>Draw <span class="math inline">\(\theta_2^{(s)} \sim \text{Gamma}(68, 45)\)</span>.</li>
<li>Compute the indicator <span class="math display">\[
I^{(s)} = \mathbf{1}\{\theta_1^{(s)} &gt; \theta_2^{(s)}\}.
\]</span></li>
</ol>
<p>Then</p>
<p><span class="math display">\[
\Pr(\theta_1 &gt; \theta_2 \mid y)
\approx
\frac{1}{S}
\sum_{s=1}^S I^{(s)}.
\]</span></p>
<p>This avoids evaluating any double integrals.</p>
</div>
<blockquote class="blockquote">
<p>Why Monte Carlo?</p>
<p>Works in high dimensions. Requires only the ability to simulate. Avoids symbolic integration. Scales to complex hierarchical models.</p>
</blockquote>
<p>This is the foundation of modern Bayesian computation.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Figure 4.1 — Monte Carlo Approximation (Gamma(68,45))</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Histograms + KDEs for S = 10, 100, 1000; true density in gray</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">8670</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Posterior: Gamma(shape=68, rate=45)</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>shape_post <span class="ot">&lt;-</span> <span class="dv">68</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>rate_post  <span class="ot">&lt;-</span> <span class="dv">45</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># MC samples</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>S_list <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">1000</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>mc_df <span class="ot">&lt;-</span> <span class="fu">do.call</span>(rbind, <span class="fu">lapply</span>(S_list, <span class="cf">function</span>(S) {</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">theta =</span> <span class="fu">rgamma</span>(S, <span class="at">shape =</span> shape_post, <span class="at">rate =</span> rate_post),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>             <span class="at">S =</span> <span class="fu">factor</span>(S, <span class="at">levels =</span> S_list))</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>}))</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid for true density (choose a sensible range around the mass)</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>xgrid <span class="ot">&lt;-</span> <span class="fu">seq</span>(</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qgamma</span>(<span class="fl">0.001</span>, <span class="at">shape =</span> shape_post, <span class="at">rate =</span> rate_post),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">qgamma</span>(<span class="fl">0.999</span>, <span class="at">shape =</span> shape_post, <span class="at">rate =</span> rate_post),</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">length.out =</span> <span class="dv">600</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>true_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">theta =</span> xgrid,</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">dens  =</span> <span class="fu">dgamma</span>(xgrid, <span class="at">shape =</span> shape_post, <span class="at">rate =</span> rate_post)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(mc_df, <span class="fu">aes</span>(<span class="at">x =</span> theta)) <span class="sc">+</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># histogram (density scale so it overlays with densities)</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)),</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>                 <span class="at">bins =</span> <span class="dv">18</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># KDE from MC samples</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="fl">1.1</span>) <span class="sc">+</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># True density (gray)</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> true_df, <span class="fu">aes</span>(<span class="at">x =</span> theta, <span class="at">y =</span> dens),</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>            <span class="at">linewidth =</span> <span class="fl">1.2</span>, <span class="at">color =</span> <span class="st">"gray50"</span>) <span class="sc">+</span></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> S, <span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">scales =</span> <span class="st">"free_y"</span>) <span class="sc">+</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Monte Carlo Approximation"</span>,</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>  <span class="at">subtitle =</span> <span class="fu">paste</span>(</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Histograms and KDEs for Monte Carlo samples"</span>,</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    <span class="st">"True Gamma(68, 45) density shown in gray"</span>,</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">sep =</span> <span class="st">"</span><span class="sc">\n</span><span class="st">"</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>  ),</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="fu">expression</span>(theta),</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>) <span class="sc">+</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">18</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.subtitle =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">13</span>),</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>, <span class="at">face =</span> <span class="st">"bold"</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_MC_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="numerical-evaluation" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="numerical-evaluation"><span class="header-section-number">4.5</span> Numerical Evaluation</h2>
<p>We now compare Monte Carlo approximations to quantities that can be computed analytically in this conjugate example.</p>
<p>Suppose</p>
<p><span class="math display">\[
Y_1,\dots,Y_n \mid \theta \sim \text{Poisson}(\theta),
\quad
\theta \sim \text{Gamma}(a,b).
\]</span></p>
<p>After observing <span class="math inline">\(y_1,\dots,y_n\)</span> with <span class="math inline">\(\sum y_i = sy\)</span> and sample size <span class="math inline">\(n\)</span>, the posterior distribution is</p>
<p><span class="math display">\[
\theta \mid y \sim \text{Gamma}(a+sy,\; b+n).
\]</span></p>
<div class="callout-example" title="College-Educated Group">
<p>For the birth-rate example:</p>
<ul>
<li><span class="math inline">\(a = 2\)</span></li>
<li><span class="math inline">\(b = 1\)</span></li>
<li><span class="math inline">\(sy = 66\)</span></li>
<li><span class="math inline">\(n = 44\)</span></li>
</ul>
<p>Posterior:</p>
<p><span class="math display">\[
\theta \mid y \sim \text{Gamma}(68,45).
\]</span></p>
<p>Posterior mean:</p>
<p><span class="math display">\[
\mathbb{E}[\theta \mid y]
=
\frac{a+sy}{b+n}
=
\frac{68}{45}
=
1.51.
\]</span></p>
<section id="monte-carlo-in-r" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="monte-carlo-in-r"><span class="header-section-number">4.5.1</span> Monte Carlo in R</h3>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">8670</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Posterior parameters</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>a  <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>b  <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>sy <span class="ot">&lt;-</span> <span class="dv">66</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>n  <span class="ot">&lt;-</span> <span class="dv">44</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>shape_post <span class="ot">&lt;-</span> a <span class="sc">+</span> sy</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>rate_post  <span class="ot">&lt;-</span> b <span class="sc">+</span> n</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="do">## Exact quantities</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>mean_exact <span class="ot">&lt;-</span> shape_post <span class="sc">/</span> rate_post</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>p_exact    <span class="ot">&lt;-</span> <span class="fu">pgamma</span>(<span class="fl">1.75</span>, <span class="at">shape =</span> shape_post, <span class="at">rate =</span> rate_post)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>ci_exact   <span class="ot">&lt;-</span> <span class="fu">qgamma</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>),</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>                     <span class="at">shape =</span> shape_post,</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>                     <span class="at">rate  =</span> rate_post)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Monte Carlo samples</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>theta_mc10   <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">10</span>,   shape_post, rate_post)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>theta_mc100  <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">100</span>,  shape_post, rate_post)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>theta_mc1000 <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1000</span>, shape_post, rate_post)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="do">## Function to summarize MC output</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>mc_summary <span class="ot">&lt;-</span> <span class="cf">function</span>(theta_sample) {</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">Mean        =</span> <span class="fu">mean</span>(theta_sample),</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">Prob_less   =</span> <span class="fu">mean</span>(theta_sample <span class="sc">&lt;</span> <span class="fl">1.75</span>),</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">CI_lower    =</span> <span class="fu">quantile</span>(theta_sample, <span class="fl">0.025</span>),</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">CI_upper    =</span> <span class="fu">quantile</span>(theta_sample, <span class="fl">0.975</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="do">## Build comparison table</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="at">Exact   =</span> <span class="fu">c</span>(<span class="at">Mean      =</span> mean_exact,</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>              <span class="at">Prob_less =</span> p_exact,</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>              <span class="at">CI_lower  =</span> ci_exact[<span class="dv">1</span>],</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>              <span class="at">CI_upper  =</span> ci_exact[<span class="dv">2</span>]),</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">MC_10   =</span> <span class="fu">mc_summary</span>(theta_mc10),</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>  <span class="at">MC_100  =</span> <span class="fu">mc_summary</span>(theta_mc100),</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>  <span class="at">MC_1000 =</span> <span class="fu">mc_summary</span>(theta_mc1000)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(results, <span class="dv">4</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>          Mean Prob_less CI_lower CI_upper
Exact   1.5111    0.8998   1.1734   1.8908
MC_10   1.5077    1.0000   1.3628   1.6228
MC_100  1.5033    0.8500   1.1536   1.9305
MC_1000 1.5180    0.8860   1.1810   1.8937</code></pre>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>Smax <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>theta_seq <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(Smax, <span class="at">shape =</span> shape_post, <span class="at">rate =</span> rate_post)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>cum_mean  <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(theta_seq) <span class="sc">/</span> <span class="fu">seq_along</span>(theta_seq)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cum_mean, <span class="at">type=</span><span class="st">"l"</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">"Number of draws (S)"</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">"Cumulative Monte Carlo mean"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> mean_exact, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_MC_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>xgrid <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.5</span>, <span class="fl">2.5</span>, <span class="at">length.out =</span> <span class="dv">400</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>true_pdf <span class="ot">&lt;-</span> <span class="fu">dgamma</span>(xgrid, <span class="at">shape =</span> shape_post, <span class="at">rate =</span> rate_post)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (S <span class="cf">in</span> <span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">100</span>,<span class="dv">1000</span>)) {</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">get</span>(<span class="fu">paste0</span>(<span class="st">"theta_mc"</span>, S))</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hist</span>(x, <span class="at">prob=</span><span class="cn">TRUE</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">main=</span><span class="fu">paste0</span>(<span class="st">"S = "</span>, S),</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">xlab=</span><span class="fu">expression</span>(theta),</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">border=</span><span class="st">"black"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(xgrid, true_pdf, <span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="04_MC_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
</div>
<section id="there-are-much-more-about-the-mc-method" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="there-are-much-more-about-the-mc-method"><span class="header-section-number">4.5.2</span> There are much more about the MC method</h3>
<ul>
<li>Variance reduction methods</li>
<li>Antithetic variates</li>
<li>Control variables</li>
<li>Importance Sampling</li>
<li>Stratified Sampling</li>
<li>Stratified Importance Sampling</li>
<li>etc…</li>
</ul>
<p>You may refer to my notes in Chapter 4 in the <a href="https://chikuang.github.io/course/stat8670/04-monte-carlo.html#other-methods">Computational Methods in Statistics Course</a>.</p>
</section>
<section id="mc-for-predictive-distribution" class="level3" data-number="4.5.3">
<h3 data-number="4.5.3" class="anchored" data-anchor-id="mc-for-predictive-distribution"><span class="header-section-number">4.5.3</span> MC for predictive distribution</h3>
</section>
</section>
<section id="sampling-from-predictive-distributions" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="sampling-from-predictive-distributions"><span class="header-section-number">4.6</span> 4.3 Sampling from Predictive Distributions</h2>
<p>As discussed earlier, the <strong>predictive distribution</strong> of a future random variable <span class="math inline">\(\tilde Y\)</span> is the probability distribution that reflects uncertainty about <span class="math inline">\(\tilde Y\)</span> after accounting for both:</p>
<ul>
<li>known quantities (conditioned on observed data), and<br>
</li>
<li>unknown quantities (integrated out).</li>
</ul>
<section id="sampling-model-vs-predictive-model" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="sampling-model-vs-predictive-model"><span class="header-section-number">4.6.1</span> Sampling Model vs Predictive Model</h3>
<p>Suppose <span class="math inline">\(\tilde Y\)</span> denotes the number of children for a randomly selected woman aged 40 with a college degree.</p>
<p>If the true mean birthrate <span class="math inline">\(\theta\)</span> were known, uncertainty about <span class="math inline">\(\tilde Y\)</span> would be described by the <strong>sampling model</strong> <span class="math display">\[
\Pr(\tilde Y = \tilde y \mid \theta) = p(\tilde y \mid \theta)
= \frac{\theta^{\tilde y} e^{-\theta}}{\tilde y!},
\]</span> that is, <span class="math display">\[
\tilde Y \mid \theta \sim \text{Poisson}(\theta).
\]</span></p>
<p>In practice, however, <span class="math inline">\(\theta\)</span> is unknown. Therefore, predictions must account for uncertainty in <span class="math inline">\(\theta\)</span>.</p>
<hr>
</section>
<section id="prior-predictive-distribution" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="prior-predictive-distribution"><span class="header-section-number">4.6.2</span> Prior Predictive Distribution</h3>
<p>If no data have been observed, predictions are obtained by integrating out <span class="math inline">\(\theta\)</span> using the prior distribution: <span class="math display">\[
\Pr(\tilde Y = \tilde y)
= \int p(\tilde y \mid \theta)\, p(\theta)\, d\theta.
\]</span></p>
<p>This is called the <strong>prior predictive distribution</strong>.</p>
<p>For a Poisson model with a Gamma prior, <span class="math display">\[
\theta \sim \text{Gamma}(a,b),
\]</span> the prior predictive distribution of <span class="math inline">\(\tilde Y\)</span> is <span class="math display">\[
\tilde Y \sim \text{Negative Binomial}(a,b).
\]</span></p>
</section>
<section id="posterior-predictive-distribution" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="posterior-predictive-distribution"><span class="header-section-number">4.6.3</span> Posterior Predictive Distribution</h3>
<p>After observing data <span class="math inline">\(Y_1 = y_1, \ldots, Y_n = y_n\)</span>, the relevant predictive distribution for a new observation is <span class="math display">\[
\Pr(\tilde Y = \tilde y \mid Y_1=y_1,\ldots,Y_n=y_n)
= \int p(\tilde y \mid \theta)\, p(\theta \mid y_1,\ldots,y_n)\, d\theta.
\]</span></p>
<p>This distribution is called the <strong>posterior predictive distribution</strong>.</p>
<p>For the Poisson–Gamma model, the posterior distribution is <span class="math display">\[
\theta \mid y_1,\ldots,y_n \sim \text{Gamma}\!\left(a + \sum_{i=1}^n y_i,\; b+n\right),
\]</span> and the posterior predictive distribution is again Negative Binomial.</p>
<hr>
</section>
<section id="monte-carlo-sampling-from-the-posterior-predictive-distribution" class="level3" data-number="4.6.4">
<h3 data-number="4.6.4" class="anchored" data-anchor-id="monte-carlo-sampling-from-the-posterior-predictive-distribution"><span class="header-section-number">4.6.4</span> Monte Carlo Sampling from the Posterior Predictive Distribution</h3>
<p>In many models, the posterior predictive distribution cannot be evaluated analytically. However, it can often be <strong>sampled using Monte Carlo methods</strong>.</p>
<p>The idea is simple:</p>
<ol type="1">
<li>Draw <span class="math inline">\(\theta^{(s)} \sim p(\theta \mid y_1,\ldots,y_n)\)</span><br>
</li>
<li>Draw <span class="math inline">\(\tilde Y^{(s)} \sim p(\tilde y \mid \theta^{(s)})\)</span><br>
</li>
<li>Repeat for <span class="math inline">\(s = 1,\ldots,S\)</span></li>
</ol>
<p>This produces samples <span class="math display">\[
\tilde Y^{(1)}, \ldots, \tilde Y^{(S)}
\sim p(\tilde y \mid y_1,\ldots,y_n),
\]</span> which approximate the posterior predictive distribution.</p>
<hr>
</section>
<section id="example-comparing-two-groups-poisson-model" class="level3" data-number="4.6.5">
<h3 data-number="4.6.5" class="anchored" data-anchor-id="example-comparing-two-groups-poisson-model"><span class="header-section-number">4.6.5</span> Example: Comparing Two Groups (Poisson Model)</h3>
<p>Suppose we observe two independent groups with Poisson data:</p>
<ul>
<li>Group 1: <span class="math inline">\(\sum Y_{i,1} = 217\)</span>, <span class="math inline">\(n_1 = 111\)</span><br>
</li>
<li>Group 2: <span class="math inline">\(\sum Y_{i,2} = 66\)</span>, <span class="math inline">\(n_2 = 44\)</span></li>
</ul>
<p>With a common prior <span class="math display">\[
\theta_k \sim \text{Gamma}(a,b), \quad k=1,2,
\]</span> the posterior distributions are <span class="math display">\[
\theta_1 \mid \mathbf y_1 \sim \text{Gamma}(a+217,\; b+111),
\]</span> <span class="math display">\[
\theta_2 \mid \mathbf y_2 \sim \text{Gamma}(a+66,\; b+44).
\]</span></p>
<p>Because <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span> are <strong>posterior independent</strong>, posterior predictive sampling proceeds independently for each group:</p>
<p><span class="math display">\[
\theta_1^{(s)} \sim p(\theta_1 \mid \mathbf y_1), \quad
\tilde Y_1^{(s)} \sim \text{Poisson}(\theta_1^{(s)}),
\]</span> <span class="math display">\[
\theta_2^{(s)} \sim p(\theta_2 \mid \mathbf y_2), \quad
\tilde Y_2^{(s)} \sim \text{Poisson}(\theta_2^{(s)}).
\]</span></p>
<hr>
</section>
<section id="monte-carlo-approximation-of-predictive-quantities" class="level3" data-number="4.6.6">
<h3 data-number="4.6.6" class="anchored" data-anchor-id="monte-carlo-approximation-of-predictive-quantities"><span class="header-section-number">4.6.6</span> Monte Carlo Approximation of Predictive Quantities</h3>
<p>Using Monte Carlo samples <span class="math inline">\(\{\tilde Y_1^{(s)}, \tilde Y_2^{(s)}\}\)</span>, we can approximate quantities such as <span class="math display">\[
\Pr(\tilde Y_1 &gt; \tilde Y_2 \mid \text{data})
\approx
\frac{1}{S} \sum_{s=1}^S
\mathbb{I}\bigl(\tilde Y_1^{(s)} &gt; \tilde Y_2^{(s)}\bigr).
\]</span></p>
<p>More generally, Monte Carlo samples from the posterior predictive distribution allow us to approximate:</p>
<ul>
<li>predictive probabilities,</li>
<li>predictive expectations,</li>
<li>quantiles and credible intervals,</li>
<li>functions of future observations.</li>
</ul>
<p>This flexibility is one of the main strengths of Monte Carlo methods in Bayesian analysis.</p>
</section>
<section id="checking" class="level3" data-number="4.6.7">
<h3 data-number="4.6.7" class="anchored" data-anchor-id="checking"><span class="header-section-number">4.6.7</span> Checking</h3>
<p>4.4 Posterior Predictive Model Checking</p>
<p>Posterior predictive model checking assesses whether a fitted Bayesian model can plausibly reproduce key features of the observed data.</p>
<p>We focus on women aged 40 without a college degree. The empirical distribution of the number of children for these women, together with the corresponding posterior predictive distribution, is shown in Figure 4.6.</p>
<p>In this sample of size <span class="math display">\[
n = 111,
\]</span> the number of women with exactly two children is <span class="math display">\[
y_{\text{obs}} = 38,
\]</span> which is twice the number of women with exactly one child.</p>
<p>In contrast, the posterior predictive distribution (shown in gray) suggests that sampling a woman with two children is slightly less likely than sampling a woman with one child, with probabilities approximately <span class="math display">\[
0.27 \quad \text{vs.} \quad 0.28.
\]</span></p>
<p>These two distributions appear to be in conflict: if the observed data contain twice as many women with two children as with one child, why does the model predict otherwise?</p>
<p>Possible Explanations</p>
<p>One explanation is sampling variability. The empirical distribution of a finite sample does not necessarily match the true population distribution, and with moderate sample sizes, random fluctuations can be substantial. A smooth population distribution can easily produce a bumpy empirical histogram.</p>
<p>An alternative explanation is model misspecification. In particular, the Poisson model cannot capture certain features of the data. There is no Poisson distribution with a sharp peak at <span class="math inline">\(y = 2\)</span>, whereas the empirical distribution shows exactly such behavior.</p>
<p>These explanations can be investigated systematically using Monte Carlo simulation.</p>
<p>A Posterior Predictive Discrepancy Statistic</p>
<p>Define the discrepancy statistic <span class="math display">\[
t(y) = \frac{\#{y_i = 2}}{\#{y_i = 1}},
\]</span> the ratio of the number of women with two children to the number with one child.</p>
<p>For the observed data, <span class="math display">\[
t(y_{\text{obs}}) = 2.
\]</span></p>
<p>To assess whether this value is surprising under the model, we examine the posterior predictive distribution of <span class="math inline">\(t(\tilde{Y})\)</span>.</p>
<p>Posterior Predictive Monte Carlo Procedure</p>
<p>For each Monte Carlo iteration <span class="math inline">\(s = 1, \dots, S\)</span>: 1. Sample from the posterior <span class="math display">\[
\theta^{(s)} \sim p(\theta \mid y_{\text{obs}})
\]</span> 2. Generate a posterior predictive dataset <span class="math display">\[
\tilde{Y}^{(s)} = (\tilde{y}_1^{(s)}, \dots, \tilde{y}_n^{(s)}),
\quad
\tilde{y}_i^{(s)} \stackrel{\text{i.i.d.}}{\sim} \text{Poisson}(\theta^{(s)})
\]</span> 3. Compute the discrepancy <span class="math display">\[
t^{(s)} = t(\tilde{Y}^{(s)})
\]</span></p>
<p>This yields samples <span class="math display">\[
{ t^{(1)}, \dots, t^{(S)} }
\]</span> from the posterior predictive distribution of <span class="math inline">\(t(\tilde{Y})\)</span>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Prior parameters</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Data summary (no bachelor's degree group)</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>n  <span class="ot">&lt;-</span> <span class="dv">111</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>sy <span class="ot">&lt;-</span> <span class="dv">217</span>   <span class="co"># sum(y_i)</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="do">## Storage</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>t_mc <span class="ot">&lt;-</span> <span class="fu">numeric</span>(<span class="dv">10000</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>) {</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Draw from posterior</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  theta <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> a <span class="sc">+</span> sy, <span class="at">rate =</span> b <span class="sc">+</span> n)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Posterior predictive sample</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>  y_mc <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n, theta)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Discrepancy statistic</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>  n1 <span class="ot">&lt;-</span> <span class="fu">sum</span>(y_mc <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>  n2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(y_mc <span class="sc">==</span> <span class="dv">2</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>  <span class="do">## Avoid division by zero</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>  t_mc[s] <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(n1 <span class="sc">&gt;</span> <span class="dv">0</span>, n2 <span class="sc">/</span> n1, <span class="cn">NA</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Remove undefined values</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>t_mc <span class="ot">&lt;-</span> t_mc[<span class="sc">!</span><span class="fu">is.na</span>(t_mc)]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Interpretation</p>
<p>Figure 4.6 shows the posterior predictive distribution of <span class="math inline">\(t(\tilde{Y})\)</span>, with the observed value <span class="math inline">\(t(y_{\text{obs}})\)</span> indicated by a vertical line.</p>
<p>Out of 10,000 Monte Carlo samples, only about 0.5% produce values of <span class="math display">\[
t(\tilde{Y}) \ge t(y_{\text{obs}}).
\]</span></p>
<p>This indicates that the observed discrepancy is extremely unlikely under the fitted Poisson model.</p>
<p>Conclusion</p>
<p>The posterior predictive check suggests that the Poisson model is inadequate for these data. Although it matches the posterior mean reasonably well, it fails to reproduce important distributional features.</p>
<p>This does not imply that the model is useless for all inferential goals. However, if our goal is to accurately describe the distribution of family sizes, a more flexible model is needed.</p>
<p>Posterior predictive checks provide a principled, simulation-based tool for diagnosing such failures and guiding model refinement.</p>
</section>
</section>
<section id="markov-chain-monte-carlo-mcmc-1" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="markov-chain-monte-carlo-mcmc-1"><span class="header-section-number">4.7</span> Markov Chain Monte Carlo (MCMC)</h2>
<hr>
<p>This Chapter borrows materials from Chapter 4 in Hoff (2009) and <a href="https://chikuang.github.io/course/stat8670/04-monte-carlo.html#other-methods">Chapter 4 in Computational Methods in Statistics Course</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./03_bi-1par.html" class="pagination-link" aria-label="Bayesian Inference for single parameter models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Bayesian Inference for single parameter models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link" aria-label="Summary">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>