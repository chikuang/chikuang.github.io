[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Description",
    "text": "Description\nThis course will cover the topics in the theory and practice of Bayesian statistical inference, ranging from a review of fundamentals to questions of current research interest. Motivation for the Bayesian approach. Bayesian computation, Monte Carlo methods, asymptotics. Model checking and comparison. A selection of examples and issues in modelling and data analysis. Discussion of advantages and difficulties of the Bayesian approach. This course will be computationally intensive through analysis of data sets using the R statistical computing language.\n\nPrerequisites\nMATH 4752/6752 – Mathematical Statistics II or equivalent, and the ability to program in a high-level language.\n\n\nInstructor\nChi-Kuang Yeh, Assistant Professor in the Department of Mathematics and Statistics, Georgia State University.\n\nOffice: Suite 1407, 25 Park Place.\nEmail: cyeh@gsu.edu.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#office-hour",
    "href": "index.html#office-hour",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Office Hour",
    "text": "Office Hour\nTBA",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#grade-distribution",
    "href": "index.html#grade-distribution",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Grade Distribution",
    "text": "Grade Distribution\n\nHomework – 50%\nExam – 30%\nFinal – 20%",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#assignment",
    "href": "index.html#assignment",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Assignment",
    "text": "Assignment\n\nTBA",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#midterm",
    "href": "index.html#midterm",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Midterm",
    "text": "Midterm\n\nTBA",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#topics-and-corresponding-lectures",
    "href": "index.html#topics-and-corresponding-lectures",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Topics and Corresponding Lectures",
    "text": "Topics and Corresponding Lectures\nThose chapters are based on the lecture notes. This part will be updated frequently.\n\n\n\nTopic\nLecture Covered\n\n\n\n\nIntroduction to R Programming\n1–2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#recommended-textbooks",
    "href": "index.html#recommended-textbooks",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Recommended Textbooks",
    "text": "Recommended Textbooks\n\nGelman, A., Carlin, J., Stern, H., Rubin, D., Dunson, D., and Vehtari, A. (2021). Bayesian Data Analysis, CRC Press, 3rd Ed.\nHoff, P.D. (2009). A First Course in Bayesian Statistical Methods, Springer.\nMcElreath, R. (2018). Statistical Rethinking: A Bayesian Course with Examples in R and Stan, CRC Press.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#side-readings",
    "href": "index.html#side-readings",
    "title": "STAT8310 - Bayesian Data Analysis",
    "section": "Side Readings",
    "text": "Side Readings\n\nTBA",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Quick Overview",
    "section": "",
    "text": "1.1 Why Bayesian?\nThe posterior distribution is obtained from the prior distribution and sampling model via Bayes’ rule:\n\\[p(\\theta \\mid y)=\\frac{p(y \\mid \\theta) p(\\theta)}{\\int_{\\Theta} p(y \\mid \\theta') p(\\theta') d \\theta'}.\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Overview</span>"
    ]
  },
  {
    "objectID": "intro.html#why-bayesian",
    "href": "intro.html#why-bayesian",
    "title": "1  Quick Overview",
    "section": "",
    "text": "Intuitive probability interpretation: Directly quantifies uncertainty about parameters as probability distributions\nIncorporates prior knowledge: Systematically combines domain expertise with data through the prior distribution\nPrincipled inference: Bayes’ rule provides a coherent framework for updating beliefs based on evidence\nNatural handling of uncertainty: Posterior distributions capture full uncertainty, not just point estimates\nSequential analysis: Easily updates beliefs as new data arrives (posterior becomes new prior)\nSmall sample inference: Performs well with limited data by leveraging prior information\nPrediction with uncertainty: Generates predictive distributions that quantify uncertainty in future observations\nDecision-making: Naturally incorporates loss functions for optimal decision rules\nModel comparison: Bayes factors provide a principled approach to comparing competing models",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Overview</span>"
    ]
  },
  {
    "objectID": "intro.html#some-bayesian-topics-and-their-computational-focus",
    "href": "intro.html#some-bayesian-topics-and-their-computational-focus",
    "title": "1  Quick Overview",
    "section": "1.2 Some Bayesian Topics and their Computational Focus",
    "text": "1.2 Some Bayesian Topics and their Computational Focus\n\n\n\nTable 1.1: Some of the Bayesian Topics and its computational related focuses.\n\n\n\n\n\n\n\n\n\n\nTopics\nKey Concepts / Readings\nComputing Focus\n\n\n\n\nIntroduction to Bayesian Thinking\nBayesian vs. Frequentist paradigms; Prior, likelihood, posterior\nReview of R basics and reproducible workflows\n\n\nBayesian Inference for Simple Models\nConjugate priors, Beta-Binomial, Normal-Normal, Poisson-Gamma\nSimulating posteriors, visualization\n\n\nPrior Elicitation and Sensitivity\nInformative vs. noninformative priors, Jeffreys prior\nPrior sensitivity plots\n\n\nMonte Carlo Integration\nLaw of large numbers, sampling-based inference\nRandom sampling and Monte Carlo approximation\n\n\nMarkov Chain Monte Carlo (MCMC)\nMetropolis-Hastings, Gibbs sampler\nImplementing MCMC in R\n\n\nConvergence Diagnostics\nTrace plots, autocorrelation, Gelman–Rubin statistic\ncoda, rstan, and bayesplot packages\n\n\nHierarchical Bayesian Models\nPartial pooling, shrinkage, multilevel structures\nrstanarm / brms\n\n\nMidterm Project: Bayesian Linear Regression\nPosterior inference for regression, model selection\nbrms, rstanarm, custom Gibbs samplers\n\n\nBayesian Model Comparison\nBayes factors, BIC, DIC, WAIC, LOO\nPractical comparison via cross-validation\n\n\nModel Checking and Diagnostics\nPosterior predictive checks, residual analysis\npp_check in brms\n\n\nAdvanced Computation\nHamiltonian Monte Carlo (HMC), Variational Inference\nUsing Stan and CmdStanR\n\n\nBayesian Decision Theory\nUtility functions, decision rules, loss minimization\nSimple decision problems in R\n\n\nModern Bayesian Methods\nApproximate Bayesian computation (ABC), Bayesian neural networks\nExamples via rstan or tensorflow-probability\n\n\nStudent Project Presentations\nApplications and case studies\nFull workflow demonstration in R",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Overview</span>"
    ]
  },
  {
    "objectID": "intro.html#interesting-article",
    "href": "intro.html#interesting-article",
    "title": "1  Quick Overview",
    "section": "1.3 Interesting Article:",
    "text": "1.3 Interesting Article:\n\nGoligher, E.C., Harhay, M.O. (2023). What Is the Point of Bayesian Analysis?, American Journal of Respiratory and Critical Care Medicine, 209, 485–487.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Quick Overview</span>"
    ]
  }
]