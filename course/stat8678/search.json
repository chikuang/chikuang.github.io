[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Description",
    "text": "Description\nThis course covers programming using the SAS statistical software package, and it provides an introduction to data analysis stressing the implementation using SAS.\nTopics include two main parts:\n\nSAS Programming: data management and manipulation, basic procedures, macro programming;\nData Analysis: descriptive statistical analysis, one- and two-sample inference, basic categorical data analysis, regression analysis, and other selected topics.\n\n\nPrerequisites\nMATH 4544/6544 ‚Äì Biostatistics, or equivalent.\n\n\nInstructor\nChi-Kuang Yeh, Assistant Professor in the Department of Mathematics and Statistics, Georgia State University.\n\nOffice: Suite 1407, 25 Park Place.\nEmail: cyeh@gsu.edu.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#office-hour",
    "href": "index.html#office-hour",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Office Hour",
    "text": "Office Hour\n10:00‚Äì13:00 on Monday, or by appointment.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#grade-distribution",
    "href": "index.html#grade-distribution",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Grade Distribution",
    "text": "Grade Distribution\n\nAssignments: 60%\nExam: 20%\nProject: 20%",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#assignment",
    "href": "index.html#assignment",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Assignment",
    "text": "Assignment\n\nA1, due on Jan 28, 2026\nA2, due on Feb 8, 2026",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#midterm",
    "href": "index.html#midterm",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Midterm",
    "text": "Midterm\n\nMarch 4, 2026",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#topics-and-corresponding-lectures",
    "href": "index.html#topics-and-corresponding-lectures",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Topics and Corresponding Lectures",
    "text": "Topics and Corresponding Lectures\nThose chapters are based on the lecture notes. This part will be updated frequently.\n\n\n\nStatus\nTopic\nLecture\n\n\n\n\n‚úÖ\nWelcome and Overview\n1\n\n\n\nüìò Part 1: Basics\n\n\n\n‚úÖ\nBasic SAS Operation\n2\n\n\n‚úÖ\nSAS Syntax\n3\n\n\n‚úÖ\nImport and Export Data\n4\n\n\n‚úÖ\nRandom Variable\n5\n\n\n\nüìò Part 2: Statistical Analysis\n\n\n\n\nOne Sample Problem as Example\n\n\n\n‚úÖ\nIntroduction to Statistical Inference I\n6\n\n\n‚è≥\nIntroduction to Statistical Inference II\n7\n\n\n‚è≥\nOne Sample Nonparametric Test\n8",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#recommended-textbooks",
    "href": "index.html#recommended-textbooks",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Recommended Textbooks",
    "text": "Recommended Textbooks\n\nStatistics 480: Introduction to SAS, The Pennsylvania State University.\nSAS Training, SAS Institute.\nSAS Resources, University of California, Los Angeles.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "STAT 8678 - SAS Programming & Data Analysis",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nSpecial thanks to Li-Hsiang Lin for providing the base materials given on this website.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html",
    "href": "part1_1_intro_operation.html",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "",
    "text": "1.1 Introduction to SAS\nQ: What is SAS?\nSAS (Statistical Analysis Software) is a prominent tool in the field of Data Analytics, offering a comprehensive suite for data manipulation, mining, management, and retrieval across various sources, coupled with robust statistical analysis capabilities. It excels in a range of functions including data management, statistical analysis, report generation, business modelling, application development, and data warehousing. SAS is user-friendly, featuring a point-and-click interface for those without technical expertise, while also providing deeper functionality through the SAS programming language. This software is instrumental in employing qualitative methods and processes that enhance employee productivity and business profitability.\nWithin SAS, data extraction and categorization into tables are pivotal for identifying and understanding data trends. This versatile suite supports advanced analytics, business intelligence, predictive analysis, and data management, facilitating effective operation in dynamic and compet- itive business environments. Additionally, SAS‚Äôs platform-independent nature allows it to operate seamlessly across various operating systems, including Linux, Windows, Mac, and Ubuntu. SAS provides extensive support to programmatically transform and analyze data in the comparison of drag and drop interface of other Business Intelligence tools. It provides very fine control over data manipulation and analysis.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html#introduction-to-sas",
    "href": "part1_1_intro_operation.html#introduction-to-sas",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "",
    "text": "1.1.1 SAS Installzation\nGeorgia State University (GSU) has purchased license, so we can access SAS University Edition for free!\nTo install SAS University Edition, choose from the following options:\n\nOption 1:\nDownload on your personal PC: Free SAS license available to GSU students, faculty, and staff via Technology Services (download required; check system requirements): Download from https://technology.gsu.edu/technology-services/software-equipment/university-licensed-software/ (Need to log-in from your GSU Account)\n\n\nGet Help for the Installation from &lt;https://gsutech.service-now.com/sp&gt;\n\nOption 2:\n\nOn Campus Access: SAS can be found on all GSU Library PCs: Floors 1-4 (not available on Library Macs, because there is no Mac version of SAS)\nGraduate Biostatistics Computer Lab (SPH): 6th floor of the Urban Life building (swipe card access required)\nCommon MILE Lab whose opening time is\n\nMonday & Wednesday: 9 ‚Äì 18\nTuesday & Thursday: 9 ‚Äì 17\nFriday: 9 ‚Äì 15\n\n\nOption 3:\nAccess via VLab, GSU‚Äôs Remote Desktop Environment. Download and Connect to Cisco AnyConnect Client to connect to GSU‚Äôs VPN (secureaccess.gsu.edu). Once connected to the VPN, login to VLab at: https://vlab.gsu.edu/ to access SAS.\nOption 4:\nAccess via SAS OnDemand for Academics/SAS Studio. If you do not already have one, create a SAS profile at https://welcome.oda.sas.com/ Then, sign in with credentials and click SAS¬ÆStudio to access the web-based SAS environment.\n\n\n\n1.1.2 SAS Windows\nOnce SAS has started, the screen will look similar to the following: The main SAS window is divided into several sub-windows:\n\n\nThe menu and toolbar along the top of the window\nThe explorer/results browser along the left hand side, where you can a listing of the results of successful SAS program.\nThe log to the top right. This gives you information about possible errors after you have run your SAS program.\nThe program editor below the log on the bottom right, where you create your SAS program.\nThe windows bar along the bottom for you to switch all windows.\n\nThe Editor (Program Editor) window is a text editor that facilitates writing SAS programs (code). The Log window displays system messages, errors, and resource usage and is thus used to review program statements. The Output window displays output from statistical procedures run within the SAS program; however this is no longer the default. In SAS 9.3 output is sent to the Results Viewer which opens automatically when you run a procedure that generates output. The Results window displays a map of the Output window, and is useful for navigating the results of complicated analyses. Finally, the Explorer window contains all of the data sets in the current SAS session.\nThese windows can be moved or resized as desired. Only one SAS window is active at a time. The active window will have a shaded title bar at the top of the window, and a highlighted windows bar at the bottom of the screen. In the above example, the Program Editor is the active window, with an ‚ÄùUntitled‚Äù program name. Note that the menu options for the SAS toolbar along the top of the screen depend on which window is currently active. (The active window can be changed by clicking on that window with the mouse, or by selecting the desired window from the Window menu.)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html#sas-program",
    "href": "part1_1_intro_operation.html#sas-program",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "1.2 SAS Program",
    "text": "1.2 SAS Program\nThe programming structure of SAS consists of three significant steps:\n\nDATA step: create and modify a SAS data set for follow-up analysis\nPROC step: conduct data analysis\nOUTPUT step: show the analysis results\n\n\n*Syntax of the SAS program:;\nDATA dataset name; /* Name of the data set. */\nINPUT var1,var2; /* Defines the variables in this data set. */\nNEW_VAR; /* Creates a new variable. */\nLABEL; /* Assign labels to variables. */\nDATALINES; /* Enters the data. */\nRUN;",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html#sas-dataset",
    "href": "part1_1_intro_operation.html#sas-dataset",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "1.3 SAS Dataset",
    "text": "1.3 SAS Dataset\nSAS dataset is used to organize data values in a tabular form, i.e., in the form of rows for observations and columns for variables.\n\nA SAS data set is a matrix whose each column is for each variable and whose each row for each observation (e.g., subject).\n\nData sets can be entered in the SAS programming code or can be read in from a variety of external sources, such as text files, csv files, and Microsoft Excel. In subsequent classes we will discuss reading in data sets from external files. Once a data set has been created, commands or procedures can operate on these data sets.\nOther than these steps programming structure also includes data set, label, variables, values, and run.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html#sas-examples",
    "href": "part1_1_intro_operation.html#sas-examples",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "1.4 SAS Examples",
    "text": "1.4 SAS Examples\n\n1.4.1 Creating a Dataset\nOur first task in using SAS will be to create a small dataset and ‚Äúprint‚Äù that dataset to the output window. As we mentioned in previous paragraph SAS programs usually start with a DATA step where the dataset is created. Once the dataset is available, various procedures can be run on the dataset. The example below is written in the SAS Program window. The program creates a dataset called ‚ÄúPeople‚Äù with 3 variables (columns) which are ‚Äògender‚Äô, ‚Äòheight‚Äô, and ‚Äòweight‚Äô and 14 observations (rows). Note that the values of the variables on each line are separated by one or more blanks. A few other things that you should note:\n\nAll SAS statements end with a semicolon (;)\nMore than one SAS statement can be put on a line, or a SAS statement can continue across several lines, if every statement ends with a semicolon.\nData listed as part of the program is also terminated with a semicolon. Data does not have to be entered in the program; it can also be read from files that are external to the SAS program (more on that next week)\ngender is a character variables as indicated by the $, and height and weight are numeric variables.\nOnce the dataset is created, various SAS procedures (called PROCs) can be used to analyze the data and present results. We will start with a listing of the data created with a procedure called PROC PRINT.\n\ntitle1 'STAT 8678 Example 1';\ntitle2 'Your name';\nDATA people;\nINPUT gender $ height weight;\n\nDATALINES;\nm 63 125\nm 76 195\nf 62 109\nm 75 186\nf 67 115\nf 60 120\nm 75 205\nm 71 185\nm 63 140\nf 59 135\nf 65 125\nm 68 167\nm 72 220\nf 66 155\n;\n\nPROC PRINT DATA=people;\nRUN;\nThe LOG window gives information on the execution of the program. If your program did not execute properly you should examine the log for error messages that may explain the failure. The program would then be modified if necessary and rerun.\nSAS creates a new window called the Results Viewer when the program is executed and produces output. This window is in HTML format and a new tab for the window is created below the left-hand windows.\n\n\n1.4.2 Sorting Data\nThe data can be sorted (in our case by gender) using PROC SORT by adding the following lines to the program. We can then go ahead and print our new dataset sorted by gender with the proc print step.\n\n\n\n\n\n\nNoteReminder\n\n\n\nAny procedural step we do must begin with PROC and every line must end with a semicolon and the command run;\n\n\nPROC SORT data = people;\nBY gender;\nRUN;\n\nPROC PRINT data=people;\nTITLE3 \"Raw data sorted only by gender\";\nRUN;\n\n\n\n\n\n\nNoteNote\n\n\n\nAny time we use PROC SORT our original dataset is sorted. SAS does not create a copy then sort!",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html#generating-summary-statistics",
    "href": "part1_1_intro_operation.html#generating-summary-statistics",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "1.5 Generating Summary Statistics",
    "text": "1.5 Generating Summary Statistics\nThe last procedure to be executed in this exercise is PROC UNIVARIATE. This procedure will allow us to see summary statistics for any quantitative variable. The output from PROC UNIVARIATE will be important for the early part of this statistical methods class. It will provide measures of central tendency (mean, median, mode) and measures of dispersion (variance, standard deviation, range) as well as other basic statistics.\nPROC UNIVARIATE DATA=people PLOT;\n  BY gender;\n  TITLE3 \"Univariate procedure output done separately by gender\";\n  TITLE4 \"The analysis was done for two quantitative variables\";\n  VAR HEIGHT WEIGHT;\nRUN;\nThe code below applies the procedure only to the variable gender. It can be run on any quantitative variable and it could be run on several variables at the same time by listing several variables in the VAR statement, which would provide a separate analysis for each variable.\nThe results for PROC UNIVARIATE will be listed in the results viewer.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html#other-notes",
    "href": "part1_1_intro_operation.html#other-notes",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "1.6 Other notes",
    "text": "1.6 Other notes\nOther Note\n\nSAS does not distinguish between upper-case letters or lower-case letters in the program, either can be used. However, it does distinguish between upper and lower case in datasets, so the character strings ‚ÄúCarol‚Äù, ‚Äúcarol‚Äù and ‚ÄúCAROL‚Äù would be considered different values of the variable ‚Äúname‚Äù in the program above.\nComments: Additionally, you may add comments anywhere in your program either by beginning the statement with an asterisk (*) and ending it with a semicolon (;) or by beginning with /* and ending with */. These comments may be thought of as marginal notes, and will show in the program editor and log, but not in the output window.\n\nShortcuts:\n\nF3 or the ‚Äúrunning man‚Äù: submits/run your program;\nF4: recalls text once the program editor;\nF5: directs user to the program editor;\nF6: directs user to the log;\nF7: directs user to the output;\nCtrl+E clears content in the current window.\nAlso, text can be copied with Ctrl+C, cut with Ctrl+X, or pasted with Ctrl+V.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_1_intro_operation.html#data-type",
    "href": "part1_1_intro_operation.html#data-type",
    "title": "1¬† Introduction to Basic SAS Operation",
    "section": "1.7 Data Type",
    "text": "1.7 Data Type\nWe can classify variables into quantitative variables and qualitative variables:\n\nQualitative variables yield non-numerical information. Qualitative variables are often referred to as categorical variables, such as blood type. Qualitative variables can be further classified as\n\nA nominal variable is a qualitative variable where no ordering is possible or implied in the levels, such as gender.\nA ordinal variable is a qualitative variable with an order implied in the levels, such as health ( poor, reasonable, good, or excellent)\n\nQuantitative variables yield numerical measurements. Quantitative variables can be further classified as discrete or continuous.\n\nA discrete variable can assume only a countable number of values, such as headache severity scores.\nA continuous variable is one that can take any one of an uncountable number of values in an interval, such as weight.\n\n\n\n\nQuestion:\nWhat is the type of each variable in the following dataset?\n\nAGE: The respondent‚Äôs age in years\nGENDER: The respondent‚Äôs sex coded 1 for male and 2 for female\nHAPPY: The respondent‚Äôs general happiness, coded:1 for ‚ÄúNot too happy‚Äù2 for ‚ÄúPretty happy‚Äù3 for ‚ÄúVery happy‚Äù\nTVHOURS: The average number of hours the respondent watched TV during a day\n\n\n\n\nSurvey Respondent Summary\n\n\nRespondent\nAGE\nGen\nHAPPY\nTVHOURS\n\n\n\n\n1\n41\n1\n2\n0\n\n\n2\n25\n2\n1\n0\n\n\n3\n43\n1\n2\n4\n\n\n4\n38\n1\n2\n2\n\n\n5\n53\n2\n3\n2\n\n\n6\n43\n2\n2\n6\n\n\n7\n56\n2\n2\n2\n\n\n\n\n\nAnswer:\n\nAge: Continuous variable;\nSEX: qualitative;\nHAPPY: Discrete variable;\nTVHOURS: Continuous variable",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introduction to Basic SAS Operation</span>"
    ]
  },
  {
    "objectID": "part1_2_sas_syntax.html",
    "href": "part1_2_sas_syntax.html",
    "title": "2¬† Working with SAS Syntax",
    "section": "",
    "text": "2.1 SAS Statments\nIn general, writing a SAS program is to write a sequence of steps, and a step is a sequence of SAS statements:\nSAS statements have these characteristics (Check the highlight context in the following examples):\nSAS programming statements are easier to read if you begin DATA, PROC, and RUN statements in column one and indent the other statements. This makes it more structured. Also, consistent spacing also makes a SAS program easier to read.\nOverall, we can type SAS statements in the following ways:\nSometimes we may want to make comments/notes to easy remember our SAS statements or to let other people easily understand what our code want to say. These comments are text that SAS ignores during processing. You can use comments anywhere in a SAS program to document the purpose of the program, explain segments of the program, or mark SAS code as non-executing text.\nThere are two ways to insert comments in a SAS program:\nAvoid placing the /* comment symbols in columns 1 and 2. On some operating environments, SAS might interpret these symbols as a request to end the SAS job or session. An example is given below:",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Working with SAS Syntax</span>"
    ]
  },
  {
    "objectID": "part1_2_sas_syntax.html#sas-statments",
    "href": "part1_2_sas_syntax.html#sas-statments",
    "title": "2¬† Working with SAS Syntax",
    "section": "",
    "text": "Usually begin with an identifying keyword.\nAlways end with a semicolon.\n\n\n\n\n\n\nOne or more blanks can be used to separate words.\nThey can begin and end in any column.\nA single statement can span multiple lines.\nSeveral statements can be on the same line.\n\n\n\n\n\nUsing an asterisk (*) to begin the comment and a semicolon (;) to end the comment.\n\n* This is a comment in SAS;\n\nUsing slash-asterisk (/*) to begin the comment and asterisk-slash (*/) to end the comment.\n\n/* This is a comment in SAS */",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Working with SAS Syntax</span>"
    ]
  },
  {
    "objectID": "part1_2_sas_syntax.html#diagnosing-and-correcting-syntax-errors",
    "href": "part1_2_sas_syntax.html#diagnosing-and-correcting-syntax-errors",
    "title": "2¬† Working with SAS Syntax",
    "section": "2.2 Diagnosing and Correcting Syntax Errors",
    "text": "2.2 Diagnosing and Correcting Syntax Errors\nSyntax errors occur when program statements do not conform to the rules of the SAS language.\nExamples of syntax errors:\n\nmisspelled keywords\nunmatched quotation marks\nmissing semicolons\ninvalid options\n\nWhen SAS encounters a syntax error, SAS prints a warning or an error message to the log; for example,\n\nWhen SAS encounters a syntax error, SAS underlines the error and the following information is written to the SAS log:\n\nthe word ERROR or WARNING\nthe location of the error + an explanation of the error\n\n\nThis program has three syntax errors. What are the errors?",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Working with SAS Syntax</span>"
    ]
  },
  {
    "objectID": "part1_2_sas_syntax.html#solution-to-the-example",
    "href": "part1_2_sas_syntax.html#solution-to-the-example",
    "title": "2¬† Working with SAS Syntax",
    "section": "2.3 Solution to the example",
    "text": "2.3 Solution to the example\n\nExercise 1: 5\nExercise 2:",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Working with SAS Syntax</span>"
    ]
  },
  {
    "objectID": "part1_3_import_export.html",
    "href": "part1_3_import_export.html",
    "title": "3¬† Import and Export Dataset",
    "section": "",
    "text": "3.1 Reading from External Files\nOne of the strengths of SAS as a data analysis tool is its ability to read data from many sources, subset or combine data sets, and modify the datasets to accomplish various tasks. The most common types of external data sets used in SAS are EXCEL files (XLS extent), comma separated value files (CSV extent) and various space separate text files (PRN or TXT extent). A CSV file is actually a text file and can be read in any text reader (NOTEPAD or WORDPAD in Windows). In fact, the SAS files themselves, as well as the LOG and the LST files produced by a SAS by a batch submit, are also simple text files.\nThe PROC IMPORT statement is the best way to enter external data sets. The CSV file we will be using is called ‚Äúgrades.csv‚Äù. Download and save it in your favourite folder and mark the complete path to it. Then use the following code to import it, making sure you put the correct path on the DATAFILE argument.\nThe IMPORT statement reads the dataset and stores it as the value designated by ‚ÄúOUT‚Äù in this case it will be saved as ‚ÄúGrades‚Äù in the library ‚ÄúWork‚Äù.\nThe DBMS statement defines the type of input SAS should be reading. The following table gives you all the possible choices. The REPLACE argument forces SAS to overwrite any older datasets with the same name.\nThe GETNAMES = YES or NO statement for spreadsheets and delimited external files, determines whether to generate SAS variable names from the column names in the input file‚Äôs first row of data. If you specify GETNAMES = NO or if the column names are not valid SAS names, PROC IMPORT uses the variable names VAR0, VAR1, VAR2, and so on. You may replace the equals sign with a blank.\nThe DATAROW argument tells SAS where to start reading for input data. In our case it is row 2 since row 1 is used for variable names.\nWe use the print procedure to see the dataset,\nThe first few rows are shown as follows",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Import and Export Dataset</span>"
    ]
  },
  {
    "objectID": "part1_3_import_export.html#reading-from-external-files",
    "href": "part1_3_import_export.html#reading-from-external-files",
    "title": "3¬† Import and Export Dataset",
    "section": "",
    "text": "PROC IMPORT OUT= GRADES_temp\n  DATAFILE= \"Put Your Path Here/grades_temp.csv\" DBMS=CSV REPLACE;\n  GETNAMES=YES;\n  DATAROW=2;\nRUN;\n\n\n\n\n\nPROC PRINT DATA=GRADES_temp;\nRUN",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Import and Export Dataset</span>"
    ]
  },
  {
    "objectID": "part1_3_import_export.html#export-a-file-from-sas",
    "href": "part1_3_import_export.html#export-a-file-from-sas",
    "title": "3¬† Import and Export Dataset",
    "section": "3.2 Export a File from SAS",
    "text": "3.2 Export a File from SAS\nAfter reading a dataset into SAS, we may need to conduct some initial step/analysis to re-organize dataset for doing further data analysis. In the grade example, the first row shows the maximum points available for each quiz. We need to remove this row so that our analysis is correct. This can be done by the following SAS code\nDATA GRADES;\n  SET GRADES_temp NOBS=COUNT\n    IF _n_        &lt;= 1 THEN DELETE;\nRUN;\nNote: GRADES_temp is the name of the old dataset and GRADES is the name of the new dataset after the first row is deleted.\nAfter re-organize the dataset, we may want to export the updated dataset for use in the future:\nThis can be done by\nPROC EXPORT DATA= GRADES\n  OUTFILE= \"Put Your Path Here/grade_v2.csv\" DBMS=CSV REPLACE;\n  REPLACE;\nRUN;\nWe will talk about more reorganizing skills in SAS in the next topic.\n\nWhich statement is true concerning the DATALINES statement based on reading the comment?\n\nThe DATALINES statement is used when reading data located in a raw data file.\nThe DATALINES statement is used when reading data located directly in the program.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Import and Export Dataset</span>"
    ]
  },
  {
    "objectID": "part1_3_import_export.html#import-export-in-sas-virtual-studio",
    "href": "part1_3_import_export.html#import-export-in-sas-virtual-studio",
    "title": "3¬† Import and Export Dataset",
    "section": "3.3 Import & Export in SAS Virtual Studio",
    "text": "3.3 Import & Export in SAS Virtual Studio\nThe key is\n\nUpload data before conducting ‚ÄúImport‚Äù\nDownload data after conducting ‚ÄúExport‚Äù\n\n\nA example given below will be demonstrated during the class.\n/* Generated Code (IMPORT) */\n/* Source File: grades_temp.csv */\n/* Source Path: /home/u63733881/sasuser.v94 */\n/* Code generated on: 1/20/24, 3:49 PM */\n\n%web_drop_table(WORK.IMPORT);\n\nFILENAME REFFILE '/home/u63733881/sasuser.v94/grades_temp.csv';\n\nPROC IMPORT DATAFILE=REFFILE\n    DBMS=CSV\n    OUT=WORK.grades_temp;\n    GETNAMES=YES;\nRUN;\n\nPROC CONTENTS DATA=WORK.grades_temp; \nRUN;\n\nPROC print data=WORK.grades_temp;\nRUN;\n\nDATA WORK.grades;\nSET WORK.grades_temp NOBS=COUNT;\nIF _n_ &lt;= 1 THEN DELTE;\nRUN;\n\nPROC PRINT DATA=WORK.grades;\nRUN;\n\nPROC EXPORT data=WORK.grades\n    OUTFILE = \"/home/u63733881/sasuser.v94/grades_2.csv\"\n    DBMS = csv\n    REPLACE;\nRUN;",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Import and Export Dataset</span>"
    ]
  },
  {
    "objectID": "part1_3_import_export.html#solution-to-the-example",
    "href": "part1_3_import_export.html#solution-to-the-example",
    "title": "3¬† Import and Export Dataset",
    "section": "3.4 Solution to the example",
    "text": "3.4 Solution to the example\nAnswer of the example: b",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Import and Export Dataset</span>"
    ]
  },
  {
    "objectID": "part1_4_rv.html",
    "href": "part1_4_rv.html",
    "title": "4¬† Random Variables",
    "section": "",
    "text": "4.1 What Is a Random Variable?\nA random variable (RV) is a numerical quantity whose value depends on the outcome of a random experiment.\nWe typically denote a random variable by an uppercase letter, such as \\(X\\) and its realized value by a lowercase letter, such as \\(X = x\\). The random variable can be continuous or discrete.\nIn practice, we often observe multiple realizations, or running the random experiment multiple times, say \\(n\\) times or \\(n\\) realizations. We denote these realizations as: \\[X_1 = x_1, \\; X_2 = x_2, \\; \\ldots, \\; X_n = x_n.\\] The number \\(n\\) is called the sample size.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "part1_4_rv.html#what-is-a-random-variable",
    "href": "part1_4_rv.html#what-is-a-random-variable",
    "title": "4¬† Random Variables",
    "section": "",
    "text": "Define whether the following random variables are discrete or continuous, and the possible values that \\(X\\) takes.\n\nNumber of emails received by a server in one hour (\\(X = 0, 1, 2, \\ldots\\): discrete)\nTime (in minutes) until a machine fails (\\(X = x \\in [0, \\infty)\\): continuous)\nTotal number of defects on a manufactured item (\\(X = 0, 1, 2, \\ldots\\): discrete)\nDaily maximum temperature in Atlanta (in degrees Fahrenheit) (\\(X = x \\in (-\\infty, \\infty)\\): continuous)\nWhether a randomly selected loan defaults within one year (\\(X = 1 \\text{ if default, } 0 \\text{ otherwise}\\): discrete)\n\n\n\nDefine whether the following random variables are discrete or continuous, and the possible values that \\(X\\) takes.\n\nNumber of transactions made by a customer in a day\nResponse time (in seconds) of a web service request\nCount of hospital admissions in a city per week discrete)\nProportion of time a system is idle during a day",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "part1_4_rv.html#discrete-vs-continuous-random-variables",
    "href": "part1_4_rv.html#discrete-vs-continuous-random-variables",
    "title": "4¬† Random Variables",
    "section": "4.2 Discrete vs Continuous Random Variables",
    "text": "4.2 Discrete vs Continuous Random Variables\n\n4.2.1 Discrete Random Variables\nA discrete random variable takes values in a finite or countable set.\nExamples:\n\nNumber of heads in three coin flips\nNumber of students passing an exam\nNumber of events occurring in a fixed time period\n\nA discrete random variable is described by a probability mass function (PMF):\n\n\n\nValue of \\(X\\)\n\\(x_1\\)\n\\(x_2\\)\n\\(x_3\\)\n‚Ä¶\n\\(x_m\\)\n\n\n\n\nProbability\n\\(p_1\\)\n\\(p_2\\)\n\\(p_3\\)\n‚Ä¶\n\\(p_m\\)\n\n\n\nThese probabilities satisfy:\n\n\\(0 \\le p_i \\le 1\\),\n\\(\\sum_{i=1}^m p_i = 1\\).\n\nWe calculate the probability of events modelled by discrete random variables by summing up the probability \\(p_i\\) for the values \\(x_i\\) that make up the event.\n\nSuppose the length \\(X\\) (in minutes) of an international phone call has distribution:\n\n\n\nX\n1\n2\n3\n4\n\n\n\n\nP(X)\n0.2\n0.5\n0.2\n0.1\n\n\n\nThen, calculate the following probabilities\n\n\\(P(X \\le 2)\\)\n\\(P(X &lt; 2)\\)\n\\(P(X &gt; 1)\\)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "part1_4_rv.html#common-discrete-distributions",
    "href": "part1_4_rv.html#common-discrete-distributions",
    "title": "4¬† Random Variables",
    "section": "4.3 Common Discrete Distributions",
    "text": "4.3 Common Discrete Distributions\n\n4.3.1 Bernoulli Distribution\nUsed for binary outcomes:\n\nsuccess / failure\nyes / no\n1 / 0\n\nNotation: \\(X \\sim \\text{Ber}(p)\\), where \\(p\\) is the probability of success.\nExample:\nWhether a patient has diabetes (1 = yes, 0 = no).\nHow to specify the probability \\(p\\) will be discussed in the following lecture. This is related to the procedure of statistical inference.\n\n\n4.3.2 Poisson Distribution\nUsed to model counts of events over time or space.\nNotation: \\(X \\sim \\text{Poi}(\\lambda)\\)\nwhere \\(\\lambda\\) is the mean rate.\nExamples:\n\nNumber of trades per day\nNumber of system failures per week\nNumber of arrivals to a service queue\n\nSimilar to the probability \\(p\\) from the Bernoulli distribution, how to specify the rate \\(\\lambda\\) will be discussed in the following lecture.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "part1_4_rv.html#continuous-random-variables",
    "href": "part1_4_rv.html#continuous-random-variables",
    "title": "4¬† Random Variables",
    "section": "4.4 Continuous Random Variables",
    "text": "4.4 Continuous Random Variables\nA continuous random variable can take any value \\(x\\) in an interval.\nExamples:\n\nHeight of individuals\nTime until failure of a component\nTest scores treated as continuous\n\nProbabilities are defined using density functions, not point probabilities. Some common continuous distributions are as follows.\n\n4.4.1 Normal Distribution\nThe normal distribution is also called the Gaussian distribution. It is characterized by two parameters: the mean \\(\\mu\\) and the standard deviation \\(\\sigma\\). It is unimodal and symmetric around the mean which is the centre of the mass. A continuous random variable \\(X\\) that has a normal distribution is said to be normal or normally distributed.\nNotation: \\(X \\sim N(\\mu, \\sigma^2)\\). Sometimes the standard deviation may be used instead of the variance, which is the square of the variance.\nInstitution of the normal distribution:\n\nmean: \\(\\mu\\)\nvariance: \\(\\sigma^2\\)\n\n\n\n\n\n\n\n\n\n\nA distribution plot of the normal distribution with mean 0 and standard deviation 1 is shown above. It is often referred as the standard normal distribution. In practice, we would like to ‚Äústandardized‚Äù the data to have mean 0 and standard deviation 1 for the subsequent analysis.\nNormal distribution play an important role in statistical inference. One of the important property is the 68-95-99.7 rule: - About 68% of the data falls within one standard deviation of the mean - About 95% of the data falls within two standard deviations of the mean - About 99.7% of the data falls within three standard deviations of the mean\n\n\n\n\n\n\n\n\n\n\n\n4.4.2 Exponential Distribution\nThe exponential distribution is another common distribution where a few outcomes are most likely with a rapidly decreasing probability for larger values. It is often used to model waiting times or lifetimes of objects. It is similar to the geometric distribution in the discrete case.\nTwo ways to specify the parameter.\n\n\\(X \\sim \\text{Exp}(\\lambda)\\), where \\(\\lambda\\) is the rate parameter.\n\\(X \\sim \\text{Exp}(\\beta)\\), where \\(\\beta\\) is the scale parameter, and \\(\\beta = 1/\\lambda\\).\n\nThe notation is either \\(X \\sim \\text{Exp}(\\lambda)\\) or \\(X \\sim \\text{Exp}(\\beta)\\). But to be sure which parameterization is used, we need to check the definition of the distribution.\n\nPlease define adequate random variables for the following data example, and thaink about what distribution can be used to model the data.\n\nSuppose we want to know whether the rate of diabetes of a certain area is too high. The researchers randomly discuss with 10 individuals in a certain area to know whether they have diabetes. The data are collected as ‚Äúyes‚Äù or ‚Äúno‚Äù answers as follows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIndividual\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nOutcome\n1\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n\n\nA comapny that manufactures light blulb claims that a particular type of light bulb will last 850 hours on average. To justify the claim more scientifically, a researcher randomly selects 10 light bulbs of that type and measures the lifetimes (in hours) of the light bulbs as follows:\n\n\n\n\nLight Bulb\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n\n\n831\n832\n840\n819\n822\n836\n829\n817\n\n\n\n\nIn the following classes we will assume the dataset we have can be well-modelled represented for the underline studies. The data collection, however, is beyond the scope of the class. For those interested in data collection, please refer to the survey sampling or experimental design area.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "part1_4_rv.html#solution-to-the-exercise",
    "href": "part1_4_rv.html#solution-to-the-exercise",
    "title": "4¬† Random Variables",
    "section": "4.5 Solution to the exercise",
    "text": "4.5 Solution to the exercise\nAnswer of the exercise\nExercise 1\n\nNumber of transactions made by a customer in a day (\\(X = 0, 1, 2, \\ldots\\): discrete)\nResponse time (in seconds) of a web service request (\\(X = x &gt; 0\\): continuous)\nCount of hospital admissions in a city per week (\\(X = 0, 1, 2, \\ldots\\): discrete)\nProportion of time a system is idle during a day (\\(X = x \\in [0,1]\\): continuous)\n\nExercise 2:\n\n\\(P(X \\le 2) = 0.7\\)\n\\(P(X &lt; 2) = 0.2\\)\n\\(P(X &gt; 1) = 0.8\\)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Random Variables</span>"
    ]
  },
  {
    "objectID": "part2_1_intro_inference1.html",
    "href": "part2_1_intro_inference1.html",
    "title": "5¬† Introduction to Statistical Inference I",
    "section": "",
    "text": "5.1 Probability versus Statistics\nThere are three common goals of statistical inference:",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to Statistical Inference I</span>"
    ]
  },
  {
    "objectID": "part2_1_intro_inference1.html#probability-versus-statistics",
    "href": "part2_1_intro_inference1.html#probability-versus-statistics",
    "title": "5¬† Introduction to Statistical Inference I",
    "section": "",
    "text": "In probability, we assume that random variables\n\\(X_1, \\ldots, X_n\\) follow a distribution with known parameters.\nUnder this model, we can calculate probabilities of events of interest.\nIn statistics, although we still use a distribution to model\n\\(X_1, \\ldots, X_n\\), the parameters of the distribution are assumed to be unknown.\nOur primary goal is to use observed data, the realization\n\\(X_1 = x_1, \\ldots, X_n = x_n\\)‚Äîto make inference about these unknown parameters.\n\n\n\nPoint estimation\nInterval estimation\nHypothesis testing\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there may be multiple valid methods for achieving each goal, even when working with the same dataset.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to Statistical Inference I</span>"
    ]
  },
  {
    "objectID": "part2_1_intro_inference1.html#example-one-sample-mean-problem",
    "href": "part2_1_intro_inference1.html#example-one-sample-mean-problem",
    "title": "5¬† Introduction to Statistical Inference I",
    "section": "5.2 Example: One-Sample Mean Problem",
    "text": "5.2 Example: One-Sample Mean Problem\nThe term one sample does not mean that there is only one observation. Instead, it means that there is one population under study.\nIn this problem, we are interested in making inference about the population mean, denoted by \\(\\mu\\).\n\n5.2.1 Problem Formulation\nSuppose we want to conduct statistical inference on the mean length of a certain type of court case. Let \\[\n\\mu = \\text{the mean length of a certain type of court case}.\n\\]\nHowever, the true value of \\(\\mu\\) is unknown because we cannot observe all realizations of this process. As a result, statistical inference is required.\nIf \\(\\mu\\) were known, no inference would be necessary. What we can do in practice is to collect data. Suppose we randomly select 20 court cases of the same type from historical records and observe their case lengths (in days):\n\\[\n43,\\; 90,\\; 84,\\; 87,\\; 116,\\; 95,\\; 86,\\; 99,\\; 93,\\; 92,\n\\] \\[\n121,\\; 71,\\; 66,\\; 98,\\; 79,\\; 102,\\; 60,\\; 112,\\; 105,\\; 98.\n\\]\nFrom a statistical perspective, these observed values are treated as realizations of random variables. Specifically, we denote\n\\[\nX_1 = 43,\\; X_2 = 90,\\; \\ldots,\\; X_{20} = 98.\n\\]\nTo model the data, we assume that the random variables \\[\nX_1, X_2, \\ldots, X_{20}\n\\] are independent and identically distributed according to a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), that is,\n\\[\nX_i \\stackrel{\\text{i.i.d.}}{\\sim} N(\\mu, \\sigma^2),\n\\qquad i = 1, \\ldots, 20.\n\\]\nHere, both \\(\\mu\\) and \\(\\sigma^2\\) are unknown parameters. In this example, our primary interest lies in estimating the population mean \\(\\mu\\), while the variance \\(\\sigma^2\\) is treated as a nuisance parameter.\nWe can use the maximum likelihood estimator (MLE) or the method of moments estimator (MME) to construct a point estimator of \\(\\mu\\). Under this model, however, they are coincide. The resulting estimator is the sample mean, denoted by\n\\[\n\\hat{\\mu} = \\bar{X}_{20},\n\\]\nwhere\n\\[\n\\bar{X}_{20} = \\frac{1}{20} \\sum_{i=1}^{20} X_i.\n\\]\nUnder the assumed model, we may use either the maximum likelihood estimator or the method of moments to construct a point estimator for the population mean \\(\\mu\\). In this model, both methods lead to the same estimator: the sample mean. We denote this estimator by\n\\[\n\\hat{\\mu} = \\bar{X}_n.\n\\]\nPay careful attention to the notation. We use a capital letter \\(\\bar{X}_n\\) to emphasize that the estimator itself is a random variable. Since the estimator is a function of the random variables \\(X_1, \\ldots, X_n\\), it is also random and therefore follows a probability distribution. The probability distribution of an estimator is called its sampling distribution. We will return to the concept of sampling distributions later in the course.\n\n\n5.2.2 Formal Definitions\nTo be more precise, we introduce the following definitions.\n\nA statistic is any function of the random variables \\(X_1, \\ldots, X_n\\). Because it is a function of random variables, a statistic is itself a random variable and therefore has a probability distribution. If we use the parametric model to describe it, then there is a distribution that depends on the unknown parameters.\nA (point) estimator of a parameter \\(\\theta\\), denoted by \\(\\hat{\\theta}\\), is a statistic used to estimate \\(\\theta\\). (Note, an estimator is a random variable because it is a statistics).\nA (point) estimate is the numerical value obtained by evaluating the estimator using the observed data \\(x_1, \\ldots, x_n\\). In particular, we use lowercase notation to indicate an estimate. For example, \\(\\bar{x}_n\\) denotes the observed value of the estimator \\(\\bar{X}_n\\).\n\nSo far, we have constructed a point estimator (and hence a point estimate). To construct a confidence interval or perform hypothesis testing, we need to know the sampling distribution of the estimator \\(\\bar{X}_n\\).\nUnder the normal model with unknown variance, the sampling distribution can be expressed as\n\\[\n\\frac{\\bar{X} - \\mu}{S / \\sqrt{n}} \\sim t_{n-1},\n\\]\nwhere\n\\[\nS = \\sqrt{\\frac{\\sum_{i=1}^n (X_i - \\bar{X})^2}{n - 1}},\n\\]\nand \\(t_{n-1}\\) denotes the Student‚Äôs \\(t\\) distribution with \\(n - 1\\) degrees of freedom.\n\n\n5.2.3 Confidence Interval for \\(\\mu\\)\nBased on this sampling distribution, a \\((1 - \\alpha) \\times 100\\%\\) confidence interval for \\(\\mu\\) is given by\n\\[\n\\left[\n\\bar{X} - t_{n-1,\\alpha/2} \\frac{S}{\\sqrt{n}},\n\\;\n\\bar{X} + t_{n-1,\\alpha/2} \\frac{S}{\\sqrt{n}}\n\\right].\n\\]\n\n\n5.2.4 Hypothesis Testing for \\(\\mu\\)\nUsing the same sampling distribution, we can conduct one of the following hypothesis tests:\n\nTwo-sided test \\[\nH_0: \\mu = \\mu_0\n\\quad \\text{vs.} \\quad\nH_1: \\mu \\neq \\mu_0\n\\]\nLeft-tailed test \\[\nH_0: \\mu = \\mu_0\n\\quad \\text{vs.} \\quad\nH_1: \\mu &lt; \\mu_0\n\\]\nRight-tailed test \\[\nH_0: \\mu = \\mu_0\n\\quad \\text{vs.} \\quad\nH_1: \\mu &gt; \\mu_0\n\\]\n\nIn some textbooks, equivalent hypotheses are written as\n\n\\[\nH_0: \\mu = \\mu_0\n\\quad \\text{vs.} \\quad\nH_1: \\mu \\neq \\mu_0\n\\]\n\\[\nH_0: \\mu \\ge \\mu_0\n\\quad \\text{vs.} \\quad\nH_1: \\mu &lt; \\mu_0\n\\]\n\\[\nH_0: \\mu \\le \\mu_0\n\\quad \\text{vs.} \\quad\nH_1: \\mu &gt; \\mu_0\n\\]\n\nFortunately, SAS can perform point estimation, confidence interval construction, and hypothesis testing simultaneously, provided we clearly specify:\n\nThe statistical question\n(one-sample mean, one-sample variance, two-sample problem, etc.)\nThe inferential goal\n(point estimation, confidence interval, hypothesis testing)\nThe statistical model and method\n(for example, why we use the \\(t\\) distribution for the one-sample mean problem instead of the normal distribution or another alternative)\n\nOne of the main goals of this course is to help you build a mental ‚Äúlibrary‚Äù of statistical tools. Later, when you encounter a statistical question, you will be able to identify an appropriate method and then use SAS to obtain numerical results for interpretation.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to Statistical Inference I</span>"
    ]
  },
  {
    "objectID": "part2_1_intro_inference1.html#revisit-the-data-example-by-using-sas",
    "href": "part2_1_intro_inference1.html#revisit-the-data-example-by-using-sas",
    "title": "5¬† Introduction to Statistical Inference I",
    "section": "5.3 Revisit the data example by using SAS",
    "text": "5.3 Revisit the data example by using SAS\nThe court length data can be read by the following DATA step:\nDATA TIME;\n  INPUT TIME @@;\nDATALINES;\n43 90 84 87 116 95 86 99 93 92\n121 71 66 98 79 102 60 112 105 98\n;\nRUN;\nThe only variable in the DATA set, time, is assumed to be normally distributed. The trailing at signs (@@) indicate that there is more than one observation on a line. The following statements invoke PROC TTEST for a one-sample t test:\nPROC TTEST H0=80 PLOTS(SHOWH0) SIDES=2 ALPHA=0.1;\n  VAR TIME;\nRUN;\n\nTHE VAR statement indicates that the time variable is being studies\nthe H0= option specifies that the mean of the time variable should be compared to the null value rather than the default value of 0\nthe PLOTS(SHOWH0) option requests that this null value be displayed on all relevant graphs\nthe SIDE=2 option specifies that a the focus of the research question, namely whether the mean count case length is not equal to 80days, rather than greater or less than 80 days (in which case you would use the SIDE=L or SIDE=U options, respectively)\nthe ALPHA=0.1 option requests 90% confidence interval rather than the default 95% confidence interval\n\nThe output is presented in the table below.\n\n\n\n\n\n\n\nNote\n\n\n\nSome SAS procedures produce graphs as automatically as they produce tables if the ODS GRAPHICS option is used. The graphs are integrated with tables in the ODS output.\n\n\n\nODS GRAPHICS ON;\n\nPROC TTEST H0=80 PLOTS(SHOWH0) SIDES=U ALPHA=0.1;\n  VAR TIME;\nRUN;\n\nODS GRAPHICS OFF;\nyou will see the following results which include the same table you see in the last figure but with two more figures. We will talk those two Figures in the following classes, especially the QQ plot.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to Statistical Inference I</span>"
    ]
  },
  {
    "objectID": "part2_1_intro_inference1.html#more-about-hypothesis-and-confidence-intervals",
    "href": "part2_1_intro_inference1.html#more-about-hypothesis-and-confidence-intervals",
    "title": "5¬† Introduction to Statistical Inference I",
    "section": "5.4 More about hypothesis and confidence intervals",
    "text": "5.4 More about hypothesis and confidence intervals\n\n5.4.1 How to construct a confidence interval?\nConsider a 95% confidence interval for the population mean \\(\\mu\\). Under the normal approximation (or by the Central Limit Theorem), we have\n\\[\nP(-1.96 &lt; Z &lt; 1.96) \\approx 0.95,\n\\]\nwhere \\(Z\\) is a standard normal random variable.\nEquivalently, this can be written as\n\\[\nP\\left(\n-1.96\n&lt;\n\\frac{\\bar{X} - \\mu}{\\sigma / \\sqrt{n}}\n&lt;\n1.96\n\\right)\n\\approx 0.95.\n\\]\n\n\n5.4.2 Rearranging the Inequality\nRearranging the terms inside the probability statement yields\n\\[\nP\\left(\n\\bar{X} - 1.96 \\frac{\\sigma}{\\sqrt{n}}\n&lt;\n\\mu\n&lt;\n\\bar{X} + 1.96 \\frac{\\sigma}{\\sqrt{n}}\n\\right)\n\\approx 0.95.\n\\]\n\n\n\n5.4.3 Large-Sample Confidence Interval\nThus, a large-sample 95% confidence interval for \\(\\mu\\) is given by\n\\[\n\\left[\n\\bar{X} - 1.96 \\frac{\\sigma}{\\sqrt{n}},\n\\;\n\\bar{X} + 1.96 \\frac{\\sigma}{\\sqrt{n}}\n\\right].\n\\]\nMore compactly, we often write this interval as\n\\[\n\\bar{X} \\pm 1.96 \\frac{\\sigma}{\\sqrt{n}}.\n\\]",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to Statistical Inference I</span>"
    ]
  },
  {
    "objectID": "part2_1_intro_inference1.html#hypothesis-testing-and-confidence-intervals-always-agree",
    "href": "part2_1_intro_inference1.html#hypothesis-testing-and-confidence-intervals-always-agree",
    "title": "5¬† Introduction to Statistical Inference I",
    "section": "5.5 3.2 Hypothesis Testing and Confidence Intervals Always Agree",
    "text": "5.5 3.2 Hypothesis Testing and Confidence Intervals Always Agree\n\n5.5.1 Interpretation of the \\(p\\)-value\nThe \\(p\\)-value is the probability of observing data at least as favorable to the alternative hypothesis \\(H_A\\) as the data actually observed, assuming the null hypothesis \\(H_0\\) is true.\nIn this example, the observed sample mean is either greater than \\(3.56\\) or less than \\(3.18\\), and the null hypothesis assumes the true population mean is \\(\\mu = 3.37\\).\n\n\n5.5.2 Computing the \\(p\\)-value\nWe compute the \\(p\\)-value as\n\\[\nP(\\bar{X} &gt; 3.56 \\text{ or } \\bar{X} &lt; 3.18 \\mid \\mu = 3.37).\n\\]\nThis can be written as the sum of two tail probabilities:\n\\[\nP(\\bar{X} &gt; 3.56 \\mid \\mu = 3.37) + P(\\bar{X} &lt; 3.18 \\mid \\mu = 3.37).\n\\]\nStandardizing using the normal distribution yields\n\\[\nP\\left(\nZ &gt; \\frac{3.56 - 3.37}{0.31 / \\sqrt{147}}\n\\right)\n+\nP\\left(\nZ &lt; \\frac{3.18 - 3.37}{0.31 / \\sqrt{147}}\n\\right).\n\\]\nEvaluating the standardized values gives\n\\[\nP(Z &gt; 7.43) + P(Z &lt; -7.43).\n\\]\nThis probability is extremely small:\n\\[\n10^{-13} \\approx 0.\n\\]\n\n\n5.5.3 Connection to Confidence Intervals\nBecause the \\(p\\)-value is essentially zero, we strongly reject \\(H_0\\) at any reasonable significance level.\nEquivalently, the hypothesized value \\(\\mu = 3.37\\) does not lie inside the corresponding confidence interval for \\(\\mu\\).\n\n\n\n\n\n\n\n\n\nThis illustrates a key principle:\n\nHypothesis testing and confidence intervals always lead to the same conclusion when they are constructed at compatible significance levels.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Introduction to Statistical Inference I</span>"
    ]
  },
  {
    "objectID": "part2_2_intro_inference2.html",
    "href": "part2_2_intro_inference2.html",
    "title": "6¬† Introduction to Statistical Inference II",
    "section": "",
    "text": "6.1 1. Recall: One-Sample Mean Problem\nIn the previous class, we studied inference for a population mean and show how to run SAS to obtain the statistical inference result from one sample \\(t\\) test. The example for illusrtratioe is to study the mean length of a certain type of the court case, i.e., \\[\n\\mu = \\text{the mean length of a certain type of court case}.\n\\] The data for the study is\n\\[\n43,\\; 90,\\; 84,\\; 87,\\; 116,\\; 95,\\; 86,\\; 99,\\; 93,\\; 92,\n\\] \\[\n121,\\; 71,\\; 66,\\; 98,\\; 79,\\; 102,\\; 60,\\; 112,\\; 105,\\; 98.\n\\] and we implement the statistical model: \\[\nX_i \\stackrel{\\text{i.i.d.}}{\\sim} N(\\mu, \\sigma^2),\n\\qquad i = 1, \\ldots, 20.\n\\]\nWith this set up, we can use SAS, such as through the following code\nand obtain the statistical results. The results let us know\nfrom \\(t\\)-distribution for the one sample mean problem.\nFrom the example, we may think the beginning of conducting statistical analysis procedure as\nIn this lecture, we will continue the remaining two steps:",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Introduction to Statistical Inference II</span>"
    ]
  },
  {
    "objectID": "part2_2_intro_inference2.html#recall-one-sample-mean-problem",
    "href": "part2_2_intro_inference2.html#recall-one-sample-mean-problem",
    "title": "6¬† Introduction to Statistical Inference II",
    "section": "",
    "text": "ODS GRAPHICS ON;\n\nPROC TTEST H0=80 PLOTS(SHOWH0) SIDES=U ALPHA=0.1;\n  VAR TIME;\nRUN;\n\nODS GRAPHICS OFF;\n\n\nA point estimate of \\(\\mu\\)\nAn interval estimate of \\(\\mu\\)\nA hypothesis testing under \\(H_0:\\mu=80\\) versus \\(H_1\\),\n\n\n\n\nFormulate the statistical problem\nCollection the adequate dataset and think the dataset as realization of some random variables\nThink some statistical models (i.e., assumptions) to be considered for the random variables. This step may include some [iv]\npreliminary data analysis\n\n\n\nModel diagnostics\n\n\nInterpret the results",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Introduction to Statistical Inference II</span>"
    ]
  },
  {
    "objectID": "part2_2_intro_inference2.html#model-diagnostics",
    "href": "part2_2_intro_inference2.html#model-diagnostics",
    "title": "6¬† Introduction to Statistical Inference II",
    "section": "6.2 Model Diagnostics",
    "text": "6.2 Model Diagnostics\nIn this step, we pause and think carefully about the assumptions underlying our analysis.\nQuestion:\n\nWhat statistical models are we implementing?\n\nIn this course, the key assumptions for the one-sample mean problem are:\n\nA normality assumption\nAn independence assumption\n\nThe independence assumption is primarily determined by how the data are collected. Once the data have been sampled, this assumption is generally not testable from the data alone.\nWe therefore assume that the sampling process was conducted correctly and focus our attention on checking the normality assumption.\nThere are two types of methods\nThere are two broad classes of methods:\n\nGraphical (visual) diagnostics\nFormal hypothesis testing methods\n\n\n6.2.1 Graphical Diagnostics for Normality\nCommon graphical tools include:\n\nHistogram and Density Plots:\nA kernel density estimate (KDE) provides a smooth estimate of the underlying probability density function, analogous to a histogram but without binning. KDEs represent the data using a continuous curve and are particularly useful for visualizing distributional shape.\nQ‚ÄìQ Plot (Quantile‚ÄìQuantile Plot)\nA Q‚ÄìQ plot compares empirical quantiles of the observed data with theoretical quantiles from a normal distribution.\nIf the normality assumption is reasonable, the points should fall approximately along a straight line.\n\n\n\n\n\n6.2.2 Formal Hypothesis Testing for Normality\nIn addition to graphical methods, we can also assess the normality assumption using formal numerical tests.\nOne commonly used method is the Kolmogorov‚ÄìSmirnov (K‚ÄìS) test, which evaluates whether a sample plausibly comes from a specified distribution, such as the normal distribution.\nThe K‚ÄìS test is widely used because many statistical procedures rely on the assumption that the data are normally distributed. When this assumption is violated, standard inference procedures may no longer be valid. The following step-by-step example demonstrates how to perform a Kolmogorov‚ÄìSmirnov test for normality using SAS.\nStep 1: Create the dataset\nDATA time;\n    INPUT time @@;\n    DATALINES;\n43 90 84 87 116 95 86 99 93 92\n121 71 66 98 79 102 60 112 105 98\n;\nRUN;\nStep 2: Perform the normality test\n/* Perform Kolmogorov‚ÄìSmirnov test */\nPROC UNIVARIATE DATA=time;\n    HISTOGRAM time / NORMAL(mu=est sigma=est);\nRUN;\n\n\n\n\n\n\n\nNoteRemarks\n\n\n\nGraphical diagnostics are informal but highly informative.\nThey allow us to detect skewness, heavy tails, and outliers that may invalidate normal-based inference.\nFormal hypothesis tests for normality will be introduced next, but should always be interpreted in conjunction with these visual tools.\n\n\n\n\n\n\n\n\nNoteImportant Note\n\n\n\nFor the best practice:\nNever rely on a single normality test. Always combine numerical tests with visual inspection.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Introduction to Statistical Inference II</span>"
    ]
  },
  {
    "objectID": "part2_2_intro_inference2.html#interpretation-of-results",
    "href": "part2_2_intro_inference2.html#interpretation-of-results",
    "title": "6¬† Introduction to Statistical Inference II",
    "section": "6.3 Interpretation of Results",
    "text": "6.3 Interpretation of Results\n\n6.3.1 Point Estimation\nPoint estimation is the process of using sample data to compute a single numerical value that estimates an unknown population parameter, such as the population mean.\nWhen we report a point estimate, it is desirable to understand whether the estimator has good statistical properties. In particular, we often examine whether a point estimator is:\n\nConsistent: As the sample size increases, the estimator becomes closer to the true parameter value.\nUnbiased: The expected value of the estimator equals the true population parameter. For example, the sample mean is an unbiased estimator of the population mean.\nEfficient (or best unbiased): Among all unbiased and consistent estimators, it has the smallest variance, meaning the estimator varies less from sample to sample.\n\nHow to rigorously verify these properties is a major topic in theoretical statistics courses. In practice, when these properties are unknown or difficult to assess, the safest interpretation of a point estimate is simply to report it with its associated unit. For example, using the court length data, we may state:\n\nA reasonable estimate for the average court length is approximately 89.85 days.\n\n\n\n6.3.2 Confidence Intervals\nA confidence interval (CI) provides a range of plausible values for an unknown population parameter. A common‚Äîbut informal‚Äîinterpretation of a 95% confidence interval is that we are ‚Äú95% confident‚Äù the true parameter lies within the interval. While this interpretation is widely used, the strictly correct interpretation is based on repeated sampling:\n\nIf the same study were repeated infinitely many times, and a 95% confidence interval were constructed each time, then approximately 95% of those intervals would contain the true parameter value.\n\nAs an example, suppose the 90% confidence interval for the population mean court length is \\([15.2,\\; 26.2].\\) This means that, under the confidence interval procedure used, intervals constructed in this way would contain the true mean in 90% of repeated samples.\nFactors Affecting Confidence Interval Width\nThe width of a confidence interval depends on several factors:\n\nSample size\nLarger samples typically produce narrower (more precise) confidence intervals.\nVariability of the outcome\nFor continuous outcomes, higher variability (larger standard deviation) leads to wider intervals.\nOutcome type\n\nFor binary outcomes, precision depends on the event probability.\nFor time-to-event outcomes, precision depends on the number of observed events.\n\n\nAll of these factors influence the standard error of the estimator, which directly determines the width of the confidence interval.\n\n\n6.3.3 Hypothesis Testing\nHypothesis testing evaluates whether observed data are consistent with a specified statistical assumption, typically called the null hypothesis.\nThe result of a hypothesis test allows us to decide whether the assumption is supported by the data or whether there is sufficient evidence to reject it. The strength of this evidence is quantified by the p-value.\nA p-value is defined as:\n\nThe probability of observing data at least as extreme as the data actually observed, assuming the null hypothesis is true.\n\nFor example, if a hypothesis test yields a p-value of 0.01, this means that‚Äîif the null hypothesis were true‚Äîthere would be only a 1% chance of observing data this extreme.\nA small p-value provides evidence against the null hypothesis, while a large p-value indicates that the data are consistent with it.\nIf the observed data are very unlikely to occur under the conditions described by the null hypothesis, then the null hypothesis is unlikely to be true. In such cases, we reject the null hypothesis in favor of the alternative hypothesis, and the result is said to be statistically significant.\nA commonly used decision rule is based on a significance level of 0.05. If the p-value is less than or equal to 0.05, this is typically taken as evidence against the null hypothesis, and we reject it in favor of the alternative hypothesis. However, a p-value cannot be used to prove that a hypothesis is true. Instead, it quantifies the strength of evidence against the null hypothesis.\n\nConsider the court length data. Suppose we conduct a hypothesis test with \\[\nH_0: \\mu = 80\n\\quad \\text{versus} \\quad\nH_1: \\mu &gt; 80,\n\\] and obtain a p-value of 0.0164.\nIf we choose a significance level of 0.05, then since \\(0.0164 &lt; 0.05,\\)\nwe reject the null hypothesis. At the 5% significance level, there is strong statistical evidence that the population mean court length is not equal to 80.\nWhen the p-value Is Large\nIf the p-value is greater than 0.05, we do not reject the null hypothesis. This does not mean that the null hypothesis is true. Rather, it means that the data do not provide strong enough evidence to conclude that the population mean court length differs from 80.\nIn hypothesis testing, failing to reject the null hypothesis should be interpreted as insufficient evidence, not as confirmation of the null hypothesis.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Introduction to Statistical Inference II</span>"
    ]
  },
  {
    "objectID": "part2_3_1sample_nonparametric_test.html",
    "href": "part2_3_1sample_nonparametric_test.html",
    "title": "7¬† One Sample Nonparametric Test",
    "section": "",
    "text": "7.1 Motivation\nA parametric test specifies certain assumptions about the distribution of responses in the population from which the sample is drawn. The validity and interpretability of parametric test results depend critically on whether these assumptions are satisfied.\nIn contrast, a nonparametric test is based on a model that imposes only very general conditions and does not assume a specific parametric form for the population distribution.\nFor this reason, nonparametric tests are often referred to as distribution-free tests.\nAlthough nonparametric methods are not completely assumption-free, the assumptions they require are generally fewer and weaker than those of parametric tests.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>One Sample Nonparametric Test</span>"
    ]
  },
  {
    "objectID": "part2_3_1sample_nonparametric_test.html#motivation",
    "href": "part2_3_1sample_nonparametric_test.html#motivation",
    "title": "7¬† One Sample Nonparametric Test",
    "section": "",
    "text": "7.1.1 Key Characteristics of Nonparametric Tests\nNonparametric test statistics typically rely on simple features of the data, such as:\n\nSigns of measurements\n\nRanks or orderings\n\nCategory or frequency counts\n\nAs a result:\n\nLinear transformations (stretching or compressing the scale) do not affect the test statistic.\nThe null distribution of the test statistic can often be derived without specifying the population distribution.\n\nNonparametric tests therefore avoid assumptions such as:\n\nNormality\nHomogeneity of variance\n\nMoreover, nonparametric methods usually compare medians rather than means, which makes them less sensitive to outliers.\nAdvantages of Nonparametric Tests\n\nApplicable to all measurement scales\nParticularly useful when the sample size is very small, unless the distribution is known\nEasier to learn and compute\nRequire fewer assumptions\nMore robust due to weaker modeling assumptions\nDo not require explicit population parameters\nIn some cases, results can be as exact as parametric procedures\n\nDisadvantages of Nonparametric Tests\n\nOften less powerful than parametric tests when parametric assumptions hold\nProvide less information about population parameters\nInterpretation is usually framed in terms of location or rank, not means\nSome procedures do not extend easily to complex models\n\nSummary\n\nParametric tests rely on strong distributional assumptions but can be powerful and informative.\nNonparametric tests trade efficiency for robustness and flexibility.\nIn practice, nonparametric methods serve as valuable alternatives when assumptions are questionable or sample sizes are limited.\n\nIn the next section, we will study specific one-sample nonparametric procedures and implement them in SAS.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>One Sample Nonparametric Test</span>"
    ]
  },
  {
    "objectID": "part2_3_1sample_nonparametric_test.html#one-sample-nonparametric-test-in-sas",
    "href": "part2_3_1sample_nonparametric_test.html#one-sample-nonparametric-test-in-sas",
    "title": "7¬† One Sample Nonparametric Test",
    "section": "7.2 One Sample Nonparametric Test in SAS",
    "text": "7.2 One Sample Nonparametric Test in SAS\nBase SAS provides two commonly used one-sample nonparametric tests through the PROC UNIVARIATE procedure:\n\nSign test\nWilcoxon signed-rank test\n\nBoth tests are designed for situations in which we want to make inference about the location of a population, typically interpreted as the median rather than the mean.\nSuppose we are interested in testing whether the median resting pulse rate of marathon runners differs from a specified value. If the normality assumption required for a one-sample t-test is questionable, nonparametric alternatives provide a robust solution.\nBy default, both tests examine the hypothesis that the median of the population from which the sample is drawn is equal to a specific value,s which is zero by dafault. However, we note that\n\nWilcoxon signed-rank test\n\nAssumes the population distribution is symmetric\nGenerally more powerful when the symmetry assumption holds\n\nSign test\n\nDoes not require symmetry\nUses only the sign of deviations from the hypothesized median\nMore robust but typically less powerful\n\n\nBoth tests can also be extended to paired (related) samples, which will be discussed later when we cover comparisons of two related samples.\nBoth the sign test and the Wilcoxon signed-rank test are automatically available in PROC UNIVARIATE.\n/* Syntax: PROC UNIVARIATE */\nPROC UNIVARIATE &lt;options&gt;;\n    BY &lt;variables&gt;;\n    CDFPLOT &lt;variables&gt; &lt;/ options&gt;;\nRUN;\n\nCLASS variable-1 &lt;(v-options)&gt; &lt;variable-2 &lt;(v-options)&gt;&gt;&lt;/ KEYLEVEL=value1 (value1 value2\n)&gt;;FREQ variable;HISTOGRAM &lt;variables&gt; &lt;/ options&gt;;ID variables;INSET keyword-list &lt;/ options&gt;;OUTPUT\n&lt;OUT=SAS-data-set&gt; &lt;keyword1=names ...keywordk=names&gt; &lt;percentile-options&gt;;PPPLOT &lt;variables&gt;\n&lt;/ options&gt;;PROBPLOT &lt;variables&gt; &lt;/ options&gt;;QQPLOT &lt;variables&gt; &lt;/ options&gt;;VAR variables;WEIGHT\nvariable;\n\nThe PROC UNIVARIATE statement invokes the UNIVARIATE procedure, which provides detailed descriptive statistics, distributional summaries, and diagnostic plots for numerical variables.\nThe VAR Statement\n\nSpecifies the numeric variables to be analyzed.\nRequired if the OUTPUT statement is used.\nIf omitted, all numeric variables in the data set are analyzed.\n\nThe PLOT statement (CDFPLOT, HISTOGRAM, PPPLOT, PROBPLOT, and QQPLOT) create graphical displays\nthe INSET statement enhances these displays by adding a table of summary statistics directly on the graph.\n\nYou can specify one or more of each of the plot statements, the INSET statement, and the OUTPUT statement. If you use a VAR statement, the variables listed in a plot statement must be a subset of the variables listed in the VAR statement.\nYou can specify a BY statement to obtain separate analyses for each BY group. The FREQ statement specifies a variable whose values provide the frequency for each observation. The ID statement specifies one or more variables to identify the extreme observations. The WEIGHT statement specifies a variable whose values are used to weight certain statistics.\nYou can use a CLASS statement to specify one or two variables that group the data into classification levels. The analysis is carried out for each combination of levels in the input data set, or within each BY group if you also specify a BY statement. You can use the CLASS statement with plot statements to create comparative displays, in which each cell contains a plot for one combination of classification levels.\n\nWe revisit the court length example to demonstrate how one-sample nonparametric tests can be used as an alternative or complement to the one-sample t-test.\nSuppose that, for some reason, we believe the t-test may not be an appropriate choice‚Äîperhaps due to concerns about normality‚Äîor we simply wish to double-check our conclusions using nonparametric methods. In this case, we can apply the nonparametric procedures available in PROC UNIVARIATE.\nStep 1: Input the Data\nWe begin by entering the court length data into SAS.\nDATA time;\n    INPUT time @@;\n    DATALINES;\n43  90  84  87  116  95  86  99  93  92\n121 71  66  98  79  102 60  112 105 98\n;\nRUN;\nStep 2: Perform a One-Sample Nonparametric Test\nTo test whether the population median court length differs from 80 days, we use PROC UNIVARIATE with the MU0= option.\n/* Perform one-sample nonparametric test */\nPROC UNIVARIATE DATA=time MU0=80;\n    VAR time;\nRUN;\nStep 3: Interpret the Output\nFrom the output, SAS provides: + Test statistics + p-values for both nonparametric tests\nThese results allow us to assess whether there is statistical evidence that the population median court length differs from 80 days, without relying on the normality assumption required by the t-test.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>One Sample Nonparametric Test</span>"
    ]
  },
  {
    "objectID": "part2_3_1sample_nonparametric_test.html#discussion-one-sided-vs-two-sided-tests",
    "href": "part2_3_1sample_nonparametric_test.html#discussion-one-sided-vs-two-sided-tests",
    "title": "7¬† One Sample Nonparametric Test",
    "section": "7.3 Discussion: One-Sided vs Two-Sided Tests",
    "text": "7.3 Discussion: One-Sided vs Two-Sided Tests\nQuestion:\nIs this a one-sided or a two-sided test?\nIn this example, SAS reports only two-sided p-values by default for the nonparametric tests in PROC UNIVARIATE. If a one-sided test is desired, SAS does not directly provide the result.\nHowever, a simple (though not exact) workaround can be used to approximate the one-sided p-value from the two-sided p-value.\n\n7.3.1 Approximate One-Sided p-Value Calculation\n\nLet\n\\[\np^* = \\frac{\\text{two-sided p-value}}{2}.\n\\]\nThen proceed according to the alternative hypothesis:\n\n\n7.3.1.1 Case 1: Right-sided test\nTesting\n\\[\nH_1: \\mu &gt; 80 \\quad (\\text{or } \\mu &gt; \\mu_0)\n\\]\n\nIf the sample mean \\(\\bar{x} &gt; \\mu_0\\), then\n\\[\n\\text{one-sided p-value} = p^*.\n\\]\nIf the sample mean \\(\\bar{x} &lt; \\mu_0\\), then\n\\[\n\\text{one-sided p-value} = 1 - p^*.\n\\]\n\n\n\n7.3.1.2 Case 2: Left-sided test\nTesting\n\\[\nH_1: \\mu &lt; 80 \\quad (\\text{or } \\mu &lt; \\mu_0)\n\\]\n\nIf the sample mean \\(\\bar{x} &lt; \\mu_0\\), then\n\\[\n\\text{one-sided p-value} = p^*.\n\\]\nIf the sample mean \\(\\bar{x} &gt; \\mu_0\\), then\n\\[\n\\text{one-sided p-value} = 1 - p^*.\n\\]\n\n\n\n\n7.3.2 Why Does This Work?\nA two-sided p-value measures evidence in both directions away from the null hypothesis. Dividing it by two isolates the probability mass in one tail of the sampling distribution.\nHowever, this adjustment is only valid when: - The test statistic is symmetric under the null hypothesis - The observed statistic is in the direction specified by the alternative\nBecause these conditions are not always guaranteed for nonparametric tests, this method should be viewed as an approximation, not an exact one-sided test.\n\n\n\n\n\n\n\n\n\n\n\nKey takeaway:\nSAS nonparametric procedures default to two-sided inference. While approximate one-sided p-values can be obtained manually, interpretation should be done with care.",
    "crumbs": [
      "Statistical Analysis",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>One Sample Nonparametric Test</span>"
    ]
  }
]